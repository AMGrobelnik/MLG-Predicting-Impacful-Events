{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:22:38.343935Z",
     "start_time": "2023-12-09T17:22:38.338638Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('../../data/batch/B_recent_10_merged_khops.pkl', 'rb') as f:\n",
    "        subgraph_ids = pickle.load(f)\n",
    "        for i in range(len(subgraph_ids)):\n",
    "            subgraph_ids[i] = (subgraph_ids[i][0], list(subgraph_ids[i][1]))\n",
    "            \n",
    "    with open('../../data/preprocessed/event_index.pkl', 'rb') as f:\n",
    "        event_index = pickle.load(f)\n",
    "        event_index = reverse_event_index(event_index)\n",
    "    return subgraph_ids, event_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:22:38.956078Z",
     "start_time": "2023-12-09T17:22:38.952553Z"
    }
   },
   "id": "1ee0df303d29ea1d"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def reverse_event_index(event_index):\n",
    "    new_index = {}\n",
    "    for file, ids in event_index.items():\n",
    "        for eid in ids:\n",
    "            new_index[eid] = file\n",
    "            \n",
    "    return new_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:22:39.544178Z",
     "start_time": "2023-12-09T17:22:39.523675Z"
    }
   },
   "id": "a911d10bc1241e7"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def save_batch(graphs, start_index):\n",
    "    for i, graph in enumerate(graphs):\n",
    "        file_name = f'batch_{str(start_index + i).zfill(5)}.pkl'\n",
    "        with open('../../data/graphs/batches/' + file_name, 'wb') as f:\n",
    "            pickle.dump(graph, f)\n",
    "\n",
    "def batch_generate(subgraph_ids, event_index, batch_size):\n",
    "    \"\"\"\n",
    "    Generates subgraphs for training\n",
    "    :param subgraph_ids: list of tuples (target_ids, neighbor_ids)\n",
    "    :param event_index: maps event ids -> file names\n",
    "    :param batch_size: number of graphs to construct at the same time\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # split subgraph_ids into batches\n",
    "    batched_ids = [subgraph_ids[i:i+batch_size] for i in range(0, len(subgraph_ids), batch_size)]\n",
    "    \n",
    "    concept_llms = load_concept_llm_files()\n",
    "    \n",
    "    # generate batches\n",
    "    i = 0\n",
    "    for batch in batched_ids:\n",
    "        graphs = []\n",
    "        \n",
    "        for target_ids, neighbor_ids in tqdm(batch, desc='Generating batches'):\n",
    "            graph = generate_subgraph(target_ids, neighbor_ids, event_index, concept_llms)\n",
    "            graphs.append(graph)\n",
    "            return graphs\n",
    "            \n",
    "        # save batch\n",
    "        save_batch(graphs, i)\n",
    "        i += batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:23:10.976638Z",
     "start_time": "2023-12-09T17:23:10.968414Z"
    }
   },
   "id": "4568cd3f25137da8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_files_to_idx(t_ids, n_ids, event_index):\n",
    "    \"\"\"\n",
    "    Maps event ids to file names\n",
    "    :param t_ids: list of target event ids\n",
    "    :param n_ids: list of neighbor event ids\n",
    "    :param event_index: maps event ids -> file names\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    file_to_idx = {}\n",
    "    for ids in [t_ids, n_ids]:\n",
    "        for eid in ids:\n",
    "            # skip events not in the dataset\n",
    "            if eid not in event_index:\n",
    "                continue\n",
    "                \n",
    "            file_name = event_index[eid]\n",
    "            if file_name not in file_to_idx:\n",
    "                file_to_idx[file_name] = set()\n",
    "                \n",
    "            file_to_idx[file_name].add(eid)\n",
    "            \n",
    "def load_concept_llm_files():\n",
    "    files = glob('../../data/text/concept_embeds/concept_embeds_*.pkl')\n",
    "    llm_files = {}\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as f:\n",
    "            llm_file = pickle.load(f)\n",
    "            llm_files[file] = llm_file\n",
    "    \n",
    "    return llm_files\n",
    "            \n",
    "def load_files(files_to_idx):\n",
    "    \"\"\"\n",
    "    Loads files into memory\n",
    "    :param files_to_idx: maps file names -> event ids\n",
    "    :return: Returns two dictionaries, one for the source files and one for the LLM files\n",
    "    \"\"\"\n",
    "    src_files = {}\n",
    "    llm_files = {}\n",
    "    for file_name, ids in files_to_idx.items():\n",
    "        with open(f'../../data/preprocessed/{file_name}.pkl', 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            src_files[file_name] = file\n",
    "        with open(f'../../data/text/embedded/{file_name}.pkl', 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            llm_files[file_name] = file\n",
    "            \n",
    "    return src_files, llm_files\n",
    "\n",
    "def add_event(graph, event_id, e_type, all_nodes, src_file, llm_file, concept_llms):\n",
    "    \"\"\"\n",
    "    Adds an event to the graph\n",
    "    :param graph:\n",
    "    :param event_id: event id to add\n",
    "    :param e_type: type of event ('event' or 'event_target')\n",
    "    :param all_nodes: list of all nodes in the graph\n",
    "    :param src_file: source file\n",
    "    :param llm_file: LLM file\n",
    "    :param concept_llms: LLM embeddings for concepts\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    event = src_file[event_id]\n",
    "    info = event['info']\n",
    "    event_counts = info['articleCounts']['total']\n",
    "    event_date = info['eventDate']\n",
    "    concepts = info['concepts']\n",
    "    similar = event['similarEvents']\n",
    "    \n",
    "    llm = llm_file[event_id]\n",
    "    llm_title, llm_summary = llm['title'], llm['summary']\n",
    "    \n",
    "    features = np.concatenate([[event_date], llm_title, llm_summary])\n",
    "    if e_type == 'event':\n",
    "        features = np.concatenate([[event_counts], features])\n",
    "    features = torch.from_numpy(features)\n",
    "    \n",
    "    target = torch.tensor([event_counts])\n",
    "    \n",
    "    # add node\n",
    "    graph.add_node(event_id, node_type=e_type, node_feature=features, node_target=target)\n",
    "    \n",
    "    # add similar event edges\n",
    "    for se in similar:\n",
    "        se_id = se['uri']\n",
    "        if se_id not in all_nodes:\n",
    "            continue\n",
    "        graph.add_edge(event_id, se_id, edge_type='similar')\n",
    "        \n",
    "    # add concepts\n",
    "    for concept in concepts:\n",
    "        concept_id = concept['id']\n",
    "        concept_llm = torch.from_numpy(concept_llms[concept_id])\n",
    "        \n",
    "        graph.add_node(concept_id, node_type='concept', node_feature=concept_llm)\n",
    "        graph.add_edge(concept_id, event_id, edge_type='related')\n",
    "        graph.add_edge(concept_id, concept_id, edge_type='concept_self')\n",
    "    \n",
    "\n",
    "def generate_subgraph(target_ids, neighbor_ids, event_index, concept_llms):\n",
    "    \"\"\"\n",
    "    Generates a subgraph for training\n",
    "    :param target_ids: list of target ids\n",
    "    :param neighbor_ids: list of neighbor ids\n",
    "    :param event_index: maps event ids -> file names\n",
    "    :param concept_llms: LLM embeddings for concepts\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # get files to idx\n",
    "    files_to_idx = get_files_to_idx(target_ids, neighbor_ids, event_index)\n",
    "    src_files, llm_files = load_files(files_to_idx)\n",
    "    all_nodes = set(target_ids + neighbor_ids)\n",
    "    \n",
    "    graph = nx.DiGraph()\n",
    "    for file_name, ids in files_to_idx.items():\n",
    "        src_file = src_files[file_name]\n",
    "        llm_file = llm_files[file_name]\n",
    "        \n",
    "        for eid in ids:\n",
    "            event_type = 'event_target' if eid in target_ids else 'event'\n",
    "            add_event(graph, eid, event_type, all_nodes, src_file, llm_file, concept_llms)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:22:40.473951Z",
     "start_time": "2023-12-09T17:22:40.472524Z"
    }
   },
   "id": "86255f48759971df"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def main():\n",
    "    subgraph_ids, event_index = load_data()\n",
    "    batch_generate(subgraph_ids, event_index, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:23:52.501640Z",
     "start_time": "2023-12-09T17:23:52.499315Z"
    }
   },
   "id": "f29214080e6e89f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-09T17:23:53.142515Z"
    }
   },
   "id": "3940f991d4479cc1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6a26c898feb71de1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
