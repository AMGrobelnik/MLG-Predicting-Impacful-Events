{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this experiment, we use t-SNE to embed events, represented by: event date, title, and summary.\n",
    "\n",
    "The key point is that we don't include article counts, but the embeddings are still partially clustered by article counts, even though they never saw them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2f7b91dd36ab75b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-17T09:52:40.273223Z",
     "start_time": "2023-12-17T09:52:34.997609Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openTSNE import TSNE\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/text/data_with_embeds.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T09:52:43.216867Z",
     "start_time": "2023-12-17T09:52:40.271100Z"
    }
   },
   "id": "e263c098553b8e15"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     lang                                              title  \\\nid                                                             \ne_11  eng                  Bombing survivor and nurse to wed   \ne_10  eng               Trade Idea: GBP/USD - Sell at 1.6450   \ne_13  eng  Too cool for Yule? Have a hipster Christmas in...   \ne_12  eng  Opening Bell: Cues that will help you trade be...   \ne_15  eng                       On Colorado shooter's arm...   \n\n                                                summary article_count  \\\nid                                                                      \ne_11  A man seriously wounded in the Boston bombing ...             7   \ne_10  Although the British pound rallied to 1.6485 y...           221   \ne_13  Unlike you, hipsters don't want any old Christ...             9   \ne_12  The Sensex plunged 210.03 points to 20,715.58 ...             1   \ne_15  (CNN) -- Colorado shooter Karl Pierson had wri...             8   \n\n     event_date                                        title_embed  \\\nid                                                                   \ne_11      16057  [0.47470707, -0.08501352, 0.26899937, -0.36353...   \ne_10      16058  [0.17094071, -0.18888026, 0.28712985, -0.36104...   \ne_13      16059  [0.2537402, -0.032281302, 0.37904784, -0.31818...   \ne_12      16054  [0.23880291, 0.03649398, 0.32137018, -0.170995...   \ne_15      16057  [0.3985864, -0.06734807, 0.40732777, -0.461210...   \n\n                                          summary_embed  \nid                                                       \ne_11  [0.3377615, -0.26158097, 0.3140225, -0.2120716...  \ne_10  [0.1786896, -0.11662727, 0.19326286, -0.20948,...  \ne_13  [0.026874868, -0.09318099, 0.03552014, -0.0260...  \ne_12  [0.46094257, -0.36103615, 0.31917268, -0.60180...  \ne_15  [0.5053371, -0.062929116, 0.27972195, -0.43177...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lang</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>article_count</th>\n      <th>event_date</th>\n      <th>title_embed</th>\n      <th>summary_embed</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>e_11</th>\n      <td>eng</td>\n      <td>Bombing survivor and nurse to wed</td>\n      <td>A man seriously wounded in the Boston bombing ...</td>\n      <td>7</td>\n      <td>16057</td>\n      <td>[0.47470707, -0.08501352, 0.26899937, -0.36353...</td>\n      <td>[0.3377615, -0.26158097, 0.3140225, -0.2120716...</td>\n    </tr>\n    <tr>\n      <th>e_10</th>\n      <td>eng</td>\n      <td>Trade Idea: GBP/USD - Sell at 1.6450</td>\n      <td>Although the British pound rallied to 1.6485 y...</td>\n      <td>221</td>\n      <td>16058</td>\n      <td>[0.17094071, -0.18888026, 0.28712985, -0.36104...</td>\n      <td>[0.1786896, -0.11662727, 0.19326286, -0.20948,...</td>\n    </tr>\n    <tr>\n      <th>e_13</th>\n      <td>eng</td>\n      <td>Too cool for Yule? Have a hipster Christmas in...</td>\n      <td>Unlike you, hipsters don't want any old Christ...</td>\n      <td>9</td>\n      <td>16059</td>\n      <td>[0.2537402, -0.032281302, 0.37904784, -0.31818...</td>\n      <td>[0.026874868, -0.09318099, 0.03552014, -0.0260...</td>\n    </tr>\n    <tr>\n      <th>e_12</th>\n      <td>eng</td>\n      <td>Opening Bell: Cues that will help you trade be...</td>\n      <td>The Sensex plunged 210.03 points to 20,715.58 ...</td>\n      <td>1</td>\n      <td>16054</td>\n      <td>[0.23880291, 0.03649398, 0.32137018, -0.170995...</td>\n      <td>[0.46094257, -0.36103615, 0.31917268, -0.60180...</td>\n    </tr>\n    <tr>\n      <th>e_15</th>\n      <td>eng</td>\n      <td>On Colorado shooter's arm...</td>\n      <td>(CNN) -- Colorado shooter Karl Pierson had wri...</td>\n      <td>8</td>\n      <td>16057</td>\n      <td>[0.3985864, -0.06734807, 0.40732777, -0.461210...</td>\n      <td>[0.5053371, -0.062929116, 0.27972195, -0.43177...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T09:52:43.359957Z",
     "start_time": "2023-12-17T09:52:43.222365Z"
    }
   },
   "id": "85280fa4d4206ba6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.65% of rows have >= 40 articles\n"
     ]
    }
   ],
   "source": [
    "print(f\"{np.sum(df['article_count'] >= 40) / df.shape[0] * 100:.2f}% of rows have >= 40 articles\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T09:52:43.363393Z",
     "start_time": "2023-12-17T09:52:43.256115Z"
    }
   },
   "id": "507af3afa5064b1c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "event_dates = df['event_date'].values.reshape(-1, 1)\n",
    "\n",
    "x = np.concatenate([event_dates, df['title_embed'].tolist(), df['summary_embed'].tolist()], axis=1)\n",
    "y = df['article_count']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T09:53:05.751629Z",
     "start_time": "2023-12-17T09:52:43.268173Z"
    }
   },
   "id": "383883d79dff0a14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train test split from pickle\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"../../data/text/tsne_train_test_noCheat.pkl\"):\n",
    "    print(\"Loading train test split from pickle\")\n",
    "    x_train, x_test, y_train, y_test = pickle.load(open(\"../../data/text/tsne_train_test_noCheat.pkl\", \"rb\"))\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    pickle.dump((x_train, x_test, y_train, y_test), open(\"../../data/text/tsne_train_test_noCheat.pkl\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-17T09:53:20.617845Z"
    }
   },
   "id": "5677b3e4087d036e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"%d training samples\" % x_train.shape[0])\n",
    "print(\"%d test samples\" % x_test.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "19fc68a9b80ab6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    perplexity=30,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "339b6d715d814508"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists(\"../data/text/llm_tsne_train_noCheat.pkl\"):\n",
    "    print(\"Loading tSNE from pickle\")\n",
    "    embedding_train = pickle.load(open(\"../../data/text/llm_tsne_train_noCheat.pkl\", \"rb\"))\n",
    "    embedding_test = pickle.load(open(\"../../data/text/llm_tsne_test_noCheat.pkl\", \"rb\"))\n",
    "else:\n",
    "    print(\"Fitting train TSNE\")\n",
    "    embedding_train = tsne.fit(x_train)\n",
    "    embedding_test = embedding_train.transform(x_test)\n",
    "    print(\"Saving to pickle\")\n",
    "    pickle.dump(embedding_train, open(\"../../data/text/llm_tsne_train_noCheat.pkl\", \"wb\"))\n",
    "    pickle.dump(embedding_test, open(\"../../data/text/llm_tsne_test_noCheat.pkl\", \"wb\"))\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2283eef3855b447f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "mask = y_train >= 40\n",
    "\n",
    "plt.scatter(embedding_train[~mask, 0], embedding_train[~mask, 1], \n",
    "            c='blue', alpha=0.8, s=5, linewidths=0, label=\"< 40 articles\")\n",
    "plt.scatter(embedding_train[mask, 0], embedding_train[mask, 1], \n",
    "            c='red', alpha=0.4, s=5, linewidths=0, label=\"40 or more articles\")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"t-SNE embedding of the articles\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dfe8938761d2193d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_idx = y_train.index\n",
    "y_counts = df.loc[train_idx]['article_count']\n",
    "counts_log = y_counts.apply(lambda x: np.log(x))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(embedding_train[:, 0], embedding_train[:, 1], \n",
    "            c=counts_log, alpha=0.8, s=5, linewidths=0, cmap='viridis')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"t-SNE embedding colored by the number of articles (log scale)\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a4005cd875a5019c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to cap values at a certain percentile\n",
    "def cap_at_percentile(s, percentile=95):\n",
    "    cap_value = np.percentile(s, percentile)\n",
    "    return np.where(s > cap_value, cap_value, s)\n",
    "\n",
    "# Apply the function within each language group\n",
    "capped_counts = df.groupby('lang')['article_count'].transform(\n",
    "    lambda x: cap_at_percentile(x, 95)\n",
    ")\n",
    "\n",
    "# Normalizing the capped counts within each language\n",
    "normalized_capped_counts = capped_counts.groupby(df['lang']).transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "\n",
    "# Getting the normalized capped counts for the training set\n",
    "normalized_capped_counts_train = normalized_capped_counts.loc[train_idx]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(embedding_train[:, 0], embedding_train[:, 1],\n",
    "                      c=normalized_capped_counts_train, alpha=0.8, s=5,\n",
    "                      linewidths=0, cmap='viridis')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"t-SNE embedding with article count capped at 95th percentile\")\n",
    "plt.colorbar(scatter, label='Normalized Capped Article Count')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b72aab306171a20c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to cap values at a certain percentile\n",
    "def cap_at_percentile(s, percentile=95):\n",
    "    cap_value = np.percentile(s, percentile)\n",
    "    return np.where(s > cap_value, cap_value, s)\n",
    "\n",
    "# Apply the function within each language group\n",
    "capped_counts = df.groupby('lang')['article_count'].transform(\n",
    "    lambda x: cap_at_percentile(x, 95)\n",
    ")\n",
    "\n",
    "# Normalizing the capped counts within each language\n",
    "normalized_capped_counts = capped_counts.groupby(df['lang']).transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "\n",
    "# Getting the normalized capped counts for the training set\n",
    "normalized_capped_counts_train = normalized_capped_counts.loc[train_idx]\n",
    "\n",
    "# Define a mapping from language to colormap\n",
    "lang_colormap = {\n",
    "    'eng': 'viridis',\n",
    "    'spa': 'inferno',\n",
    "    'deu': 'cividis',\n",
    "    'zho': 'plasma'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot each language with its own colormap\n",
    "for lang, cmap in lang_colormap.items():\n",
    "    # Filter the points for the current language\n",
    "    lang_indices = df.loc[train_idx, 'lang'] == lang\n",
    "    lang_embedding = embedding_train[lang_indices]\n",
    "    lang_counts = normalized_capped_counts_train[lang_indices]\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(lang_embedding[:, 0], lang_embedding[:, 1], \n",
    "                c=lang_counts, alpha=1, s=5, linewidths=0, cmap=cmap, label=lang)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"t-SNE embedding by language, each with its own color scale\")\n",
    "plt.colorbar(label='Normalized Capped Article Count')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a57cf8c8cfd3e93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Assuming embedding_train, df, and normalized_capped_counts_train are already defined\n",
    "\n",
    "# Define a mapping from language to colormap\n",
    "lang_colormap = {\n",
    "    'eng': 'viridis',\n",
    "    'spa': 'inferno',\n",
    "    'deu': 'magma',\n",
    "    'zho': 'plasma'\n",
    "}\n",
    "\n",
    "# Create a grid for subplots\n",
    "plt.figure(figsize=(15, 12))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "# Plot each language in a separate subplot\n",
    "for i, (lang, cmap) in enumerate(lang_colormap.items()):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    \n",
    "    # Filter the points for the current language\n",
    "    lang_indices = df.loc[train_idx, 'lang'] == lang\n",
    "    lang_embedding = embedding_train[lang_indices]\n",
    "    lang_counts = normalized_capped_counts_train[lang_indices]\n",
    "\n",
    "    # Scatter plot\n",
    "    scatter = ax.scatter(lang_embedding[:, 0], lang_embedding[:, 1],\n",
    "                         c=lang_counts, alpha=0.8, s=5, linewidths=0, cmap=cmap)\n",
    "    \n",
    "    ax.set_title(f\"t-SNE for {lang.upper()}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Adding a colorbar for each subplot\n",
    "    plt.colorbar(scatter, ax=ax, label='Normalized Capped Article Count')\n",
    "\n",
    "plt.suptitle(\"t-SNE Embedding by Language with Individual Color Scales\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "49cb203ee503fd68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "df_train = df.loc[y_train.index]\n",
    "for lang in df_train['lang'].unique():\n",
    "    mask = df_train['lang'] == lang\n",
    "    plt.scatter(embedding_train[mask, 0], embedding_train[mask, 1], \n",
    "                alpha=0.5, s=5, linewidths=0, label=lang)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"t-SNE embedding of the articles\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8b7d855d673c4396"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the test embeddings on top of the train embeddings\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Training data (blue)\n",
    "\n",
    "plt.scatter(embedding_train[:, 0], embedding_train[:, 1], \n",
    "            c='blue', alpha=1, s=5, linewidths=0, label=\"train data\")\n",
    "\n",
    "# Test data (red)\n",
    "\n",
    "plt.scatter(embedding_test[:, 0], embedding_test[:, 1], \n",
    "            c='red', alpha=0.3, s=5, linewidths=0, label=\"test data\")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"t-SNE embedding of the articles (train and test data)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3033e5f5fc6af6af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e8784e969d3786e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the KNN regressor with the number of neighbors you want to consider\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "knn.fit(X_train_scaled, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c9bdc2cc7543c653"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c3088db04668b5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the predictions vs the actual values\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# plt.scatter(y_test, y_pred, alpha=0.25, s=10, linewidths=0)\n",
    "# plt.xlabel(\"Actual values\")\n",
    "\n",
    "# color the points that are within 25% of the actual value in red\n",
    "mask = np.abs(y_test - y_pred) / y_test <= 0.25\n",
    "plt.scatter(y_test[~mask], y_pred[~mask], alpha=0.5, s=5, linewidths=0)\n",
    "plt.scatter(y_test[mask], y_pred[mask], alpha=0.5, s=5, linewidths=0, c='red')\n",
    "\n",
    "\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.title(\"KNN regression predictions vs actual values\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "efc2f59272a7d9d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_sorted = np.sort(y_pred)[::-1]\n",
    "y_test_sorted = np.sort(y_test)[::-1]\n",
    "def get_top_x_L1(percent=0.1):\n",
    "    top_percent = int(y_test.shape[0] * percent)\n",
    "    \n",
    "    y_test_p = y_test_sorted[:top_percent]\n",
    "    y_pred_p = y_pred_sorted[:top_percent]\n",
    "    \n",
    "    mean_l1_error = np.mean(np.abs(y_test_p - y_pred_p))\n",
    "    mean_relative_error = np.mean(np.abs(y_test_p - y_pred_p) / y_test_p)\n",
    "    print(f\"Mean L1 error for the top {round(x * 100)}% of rows with the most articles: {round(mean_l1_error, 2)} ({round(mean_relative_error * 100, 2)}%)\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8c83b4dfef560123"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x in [0.1, 0.2, 0.3, 0.4, 0.5, 1]:\n",
    "    get_top_x_L1(x)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1bab714e429eb498"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42ca958408f29101"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
