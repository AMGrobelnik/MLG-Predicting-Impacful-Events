{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cop\n",
    "import torch\n",
    "import deepsnap\n",
    "import deepsnap.batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.batch import Batch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import wandb\n",
    "import optuna\n",
    "import argparse\n",
    "\n",
    "from hetero_gnn import HeteroGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"hidden_size\": 81,\n",
    "    \"epochs\": 10,\n",
    "    \"weight_decay\": 0.00002203762357664057,\n",
    "    \"lr\": 0.003873757421883433,\n",
    "    \"attn_size\": 48,\n",
    "    \"num_layers\": 6,\n",
    "    \"aggr\": \"attn\",\n",
    "    \"batch_size\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
    "        super(HeteroGNNConv, self).__init__(aggr=\"mean\")\n",
    "\n",
    "        self.in_channels_src = in_channels_src\n",
    "        self.in_channels_dst = in_channels_dst\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.lin_dst = None\n",
    "        self.lin_src = None\n",
    "\n",
    "        self.lin_update = None\n",
    "\n",
    "        self.lin_dst = nn.Linear(in_channels_dst, out_channels)\n",
    "        self.lin_src = nn.Linear(in_channels_src, out_channels)\n",
    "        self.lin_update = nn.Linear(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_feature_src,\n",
    "        node_feature_dst,\n",
    "        edge_index,\n",
    "        size=None,\n",
    "        res_n_id=None,\n",
    "        ):\n",
    "\n",
    "        return self.propagate(edge_index, node_feature_src=node_feature_src, \n",
    "                    node_feature_dst=node_feature_dst, size=size, res_n_id=res_n_id)\n",
    "\n",
    "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
    "\n",
    "        out = matmul(edge_index, node_feature_src, reduce='mean')\n",
    "\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out, node_feature_dst, res_n_id):\n",
    "\n",
    "        dst_out = self.lin_dst(node_feature_dst)\n",
    "        aggr_out = self.lin_src(aggr_out)\n",
    "        aggr_out = torch.cat([dst_out, aggr_out], -1)\n",
    "        aggr_out = self.lin_update(aggr_out)\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
    "    def __init__(self, convs, args, aggr=\"mean\"):\n",
    "        \"\"\"\n",
    "        Initializes the HeteroGNNWrapperConv instance.\n",
    "\n",
    "        :param convs: Dictionary of convolution layers for each message type.\n",
    "        :param args: Arguments dictionary containing hyperparameters like hidden_size and attn_size.\n",
    "        :param aggr: Aggregation method, defaults to 'mean'.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(HeteroGNNWrapperConv, self).__init__(convs, None)\n",
    "        self.aggr = aggr\n",
    "\n",
    "        # Map the index and message type\n",
    "        self.mapping = {}\n",
    "\n",
    "        # A numpy array that stores the final attention probability\n",
    "        self.alpha = None\n",
    "\n",
    "        self.attn_proj = None\n",
    "\n",
    "        if self.aggr == \"attn\":\n",
    "\n",
    "            self.attn_proj = nn.Sequential(\n",
    "                nn.Linear(args['hidden_size'], args['attn_size']),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(args['attn_size'], 1, bias=False)\n",
    "            )\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        super(HeteroGNNWrapperConv, self).reset_parameters()\n",
    "        if self.aggr == \"attn\":\n",
    "            for layer in self.attn_proj.children():\n",
    "                layer.reset_parameters()\n",
    "    \n",
    "    def forward(self, node_features, edge_indices):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        :param node_features: Dictionary of node features for each node type.\n",
    "        :param edge_indices: Dictionary of edge indices for each message type.\n",
    "        :return: Aggregated node embeddings for each node type.\n",
    "        \"\"\"\n",
    "        \n",
    "        message_type_emb = {}\n",
    "        for message_key, message_type in edge_indices.items():\n",
    "            src_type, edge_type, dst_type = message_key\n",
    "            node_feature_src = node_features[src_type]\n",
    "            node_feature_dst = node_features[dst_type]\n",
    "            edge_index = edge_indices[message_key]\n",
    "            message_type_emb[message_key] = (\n",
    "                self.convs[message_key](\n",
    "                    node_feature_src,\n",
    "                    node_feature_dst,\n",
    "                    edge_index,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        \n",
    "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()}\n",
    "        mapping = {}        \n",
    "        \n",
    "        for (src, edge_type, dst), item in message_type_emb.items():\n",
    "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
    "            node_emb[dst].append(item)\n",
    "        self.mapping = mapping\n",
    "        \n",
    "        for node_type, embs in node_emb.items():\n",
    "            if len(embs) == 1:\n",
    "                node_emb[node_type] = embs[0]\n",
    "            else:\n",
    "                node_emb[node_type] = self.aggregate(embs)\n",
    "                \n",
    "        return node_emb\n",
    "    \n",
    "    def aggregate(self, xs):\n",
    "        \"\"\"\n",
    "        Aggregates node embeddings using the specified aggregation method.\n",
    "\n",
    "        :param xs: List of node embeddings to aggregate.\n",
    "        :return: Aggregated node embeddings as a torch.Tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.aggr == \"mean\":\n",
    "            xs = torch.stack(xs)\n",
    "            out = torch.mean(xs, dim=0)\n",
    "            return out\n",
    "\n",
    "        elif self.aggr == \"attn\":\n",
    "            xs = torch.stack(xs, dim=0)\n",
    "            s = self.attn_proj(xs).squeeze(-1)\n",
    "            s = torch.mean(s, dim=-1)\n",
    "            self.alpha = torch.softmax(s, dim=0).detach()\n",
    "            out = self.alpha.reshape(-1, 1, 1) * xs\n",
    "            out = torch.sum(out, dim=0)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
    "    \"\"\"\n",
    "    Generates convolutional layers for each message type in a heterogeneous graph.\n",
    "\n",
    "    :param hetero_graph: The heterogeneous graph for which convolutions are to be created.\n",
    "    :param conv: The convolutional layer class or constructor.\n",
    "    :param hidden_size: The number of features in the hidden layer.\n",
    "    :param first_layer: Boolean indicating if this is the first layer in the network.\n",
    "\n",
    "    :return: A dictionary of convolutional layers, keyed by message type.\n",
    "    \"\"\"\n",
    "\n",
    "    convs = {}\n",
    "\n",
    "    # Extracting all types of messages/edges in the heterogeneous graph.\n",
    "    all_messages_types = hetero_graph.message_types\n",
    "    for message_type in all_messages_types:\n",
    "        # Determine the input feature size for source and destination nodes.\n",
    "        # If it's the first layer, use the feature size of the nodes.\n",
    "        # Otherwise, use the hidden size, since from there on the size of embeddings\n",
    "        # is the same for all nodes.\n",
    "        if first_layer:\n",
    "            in_channels_src = hetero_graph.num_node_features(message_type[0])\n",
    "            in_channels_dst = hetero_graph.num_node_features(message_type[2])\n",
    "        else:\n",
    "            in_channels_src = hidden_size\n",
    "            in_channels_dst = hidden_size\n",
    "        out_channels = hidden_size\n",
    "\n",
    "        # Create a convolutional layer for this message type and add it to the dictionary.\n",
    "        convs[message_type] = conv(in_channels_src, in_channels_dst, out_channels)\n",
    "\n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hetero_graph, args, num_layers, aggr=\"mean\", return_embedding=False, mask_unknown=True):\n",
    "        \"\"\"\n",
    "        Initializes the HeteroGNN instance.\n",
    "        :param hetero_graph: The heterogeneous graph for which convolutions are to be created.\n",
    "        :param args: Arguments dictionary containing hyperparameters like hidden_size and attn_size.\n",
    "        :param num_layers: Number of graph convolutional layers.\n",
    "        :param aggr: Aggregation method 'mean' or 'attn', defaults to 'mean'.\n",
    "        :param return_embedding: Boolean indicating if the model should return embeddings or predictions.\n",
    "        :param mask_unknown: Boolean indicating if the model should mask unknown nodes (with target -1) when calculating loss.\n",
    "        \"\"\"\n",
    "        super(HeteroGNN, self).__init__()\n",
    "\n",
    "        self.aggr = aggr\n",
    "        self.hidden_size = args[\"hidden_size\"]\n",
    "        self.num_layers = num_layers\n",
    "        self.return_embedding = return_embedding\n",
    "        self.mask_unknown = mask_unknown\n",
    "\n",
    "        # Use a single ModuleDict for batch normalization and ReLU layers\n",
    "        self.bns = nn.ModuleDict()\n",
    "        self.relus = nn.ModuleDict()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.fc = nn.ModuleDict()  # Prediction heads\n",
    "\n",
    "        # Initialize graph convolutional layers for each layer and message type\n",
    "        for i in range(self.num_layers):\n",
    "            first_layer = i == 0\n",
    "            conv = HeteroGNNWrapperConv(\n",
    "                    generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer),\n",
    "                    args,\n",
    "                    self.aggr)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        # Initialize batch normalization and ReLU layers for each layer and node type\n",
    "        all_node_types = hetero_graph.node_types\n",
    "        for i in range(self.num_layers):\n",
    "            for node_type in all_node_types:\n",
    "                key_bn = f\"bn_{i}_{node_type}\"\n",
    "                key_relu = f\"relu_{i}_{node_type}\"\n",
    "                self.bns[key_bn] = nn.BatchNorm1d(self.hidden_size, eps=1.0)\n",
    "                self.relus[key_relu] = nn.LeakyReLU()\n",
    "\n",
    "        # Initialize fully connected layers for each node type\n",
    "        for node_type in all_node_types:\n",
    "            self.fc[node_type] = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, node_feature, edge_index):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        :param node_feature: Dictionary of node features for each node type.\n",
    "        :param edge_index: Dictionary of edge indices for each message type.\n",
    "        :return: The output embeddings for each node type after passing through the model.\n",
    "        \"\"\"\n",
    "        x = node_feature\n",
    "\n",
    "        # Apply graph convolutional, batch normalization, and ReLU layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)  # Apply the i-th graph convolutional layer\n",
    "            for node_type in x:\n",
    "                key_bn = f\"bn_{i}_{node_type}\"\n",
    "                key_relu = f\"relu_{i}_{node_type}\"\n",
    "                x[node_type] = self.bns[key_bn](\n",
    "                    x[node_type]\n",
    "                )  # Apply batch normalization\n",
    "                x[node_type] = self.relus[key_relu](x[node_type])  # Apply ReLU\n",
    "\n",
    "        if self.return_embedding:\n",
    "            return x\n",
    "\n",
    "        # Apply the prediction head (linear layer)\n",
    "        for node_type in x:\n",
    "            x[node_type] = self.fc[node_type](x[node_type])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, preds, y, indices):\n",
    "        \"\"\"\n",
    "        Computes the loss for the model.\n",
    "\n",
    "        :param preds: Predictions made by the model.\n",
    "        :param y: Ground truth target values.\n",
    "        :param indices: Indices of nodes for which loss should be calculated.\n",
    "\n",
    "        :return: The computed loss value.\n",
    "        \"\"\"\n",
    "\n",
    "        # mape = MeanAbsolutePercentageError().to(train_args[\"device\"])\n",
    "\n",
    "        loss = 0\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "\n",
    "        # loss_func = mape\n",
    "        # MAPE PRODUCES BETTER EVAL RESULTS BUT WORSE PREDICTIONS\n",
    "\n",
    "        if self.mask_unknown:\n",
    "            mask = y[\"event\"][indices[\"event\"], 0] != -1\n",
    "            non_zero_idx = torch.masked_select(indices[\"event\"], mask)\n",
    "\n",
    "            loss += loss_func(preds[\"event\"][non_zero_idx], y[\"event\"][non_zero_idx])\n",
    "        else:\n",
    "            # TODO: check if this is correct\n",
    "            idx = indices[\"event\"]\n",
    "            loss += loss_func(preds[\"event\"][id , y[\"event\"][idx]])\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, hetero_graph, train_idx):\n",
    "    \"\"\"\n",
    "    Trains the model on the given heterogeneous graph using the specified indices.\n",
    "\n",
    "    :param model: The graph neural network model to train.\n",
    "    :param optimizer: The optimizer used for training the model.\n",
    "    :param hetero_graph: The heterogeneous graph data.\n",
    "    :param train_idx: Indices for training nodes.\n",
    "\n",
    "    :return: The training loss as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Zero out any existing gradients\n",
    "\n",
    "    # Compute predictions using the model\n",
    "    # TODO: Use only train_idx instead of edge_index\n",
    "    # TODO: Train only on events not on concepts\n",
    "\n",
    "    preds = model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
    "\n",
    "    # Compute the loss using model's loss function\n",
    "    loss = model.loss(preds, hetero_graph.node_target, train_idx)\n",
    "\n",
    "    loss.backward()  # Backward pass: compute gradient of the loss\n",
    "    optimizer.step()  # Perform a single optimization step, updates parameters\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def test(model, graph, indices, best_model, best_tvt_scores):\n",
    "    \"\"\"\n",
    "    Tests the model on given indices and updates the best model based on validation loss.\n",
    "\n",
    "    :param model: The trained graph neural network model.\n",
    "    :param graph: The heterogeneous graph data.\n",
    "    :param indices: List of indices for training, validation, and testing nodes.\n",
    "    :param best_model: The current best model based on validation loss.\n",
    "    :param best_val: The current best validation loss.\n",
    "\n",
    "    :return: A tuple containing the list of losses for each dataset, the best model, and the best validation loss.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    tvt_scores = []\n",
    "\n",
    "    # Evaluate the model on each set of indices\n",
    "    for index in indices:\n",
    "        preds = model(graph.node_feature, graph.edge_index)\n",
    "\n",
    "        idx = index[\"event\"]\n",
    "\n",
    "        # mask = y['event'][indices['event'], 0] != -1\n",
    "        # non_zero_idx = torch.masked_select(indices['event'], mask)\n",
    "        # preds['event'][non_zero_idx], y['event'][non_zero_idx]\n",
    "\n",
    "        # non_zero_targets = torch.masked_select(graph.node_target['event'][indices['event']], mask)\n",
    "        # non_zero_truth = torch.masked_select(graph.node_target['event'][indices['event']], mask)\n",
    "\n",
    "        mask = graph.node_target[\"event\"][idx, 0] != -1\n",
    "        non_zero_idx = torch.masked_select(idx, mask)\n",
    "\n",
    "        L1 = (\n",
    "            torch.sum(\n",
    "                torch.abs(\n",
    "                    preds[\"event\"][non_zero_idx]\n",
    "                    - graph.node_target[\"event\"][non_zero_idx]\n",
    "                )\n",
    "            )\n",
    "            / non_zero_idx.shape[0]\n",
    "        )\n",
    "\n",
    "        meanRelative = (\n",
    "            torch.sum(\n",
    "                torch.abs(\n",
    "                    (\n",
    "                        preds[\"event\"][non_zero_idx]\n",
    "                        - graph.node_target[\"event\"][non_zero_idx]\n",
    "                    )\n",
    "                    / graph.node_target[\"event\"][non_zero_idx]\n",
    "                )\n",
    "            )\n",
    "            / non_zero_idx.shape[0]\n",
    "        )\n",
    "\n",
    "        tvt_scores.append((L1, meanRelative))\n",
    "\n",
    "    # Update the best model and validation loss if the current model performs better\n",
    "    if tvt_scores[1][0] < best_tvt_scores[1][0]:\n",
    "        best_tvt_scores = tvt_scores\n",
    "        # torch.to_pickle(model, 'best_model.pkl')\n",
    "        # model.to_pickle('best_model.pkl')\n",
    "\n",
    "        # best_model = copy.deepcopy(model)\n",
    "        torch.save(model.state_dict(), \"./best_model.pkl\")\n",
    "\n",
    "    return tvt_scores, best_tvt_scores, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(hetero_graph):\n",
    "    nEvents = hetero_graph.num_nodes(\"event\")\n",
    "    nConcepts = hetero_graph.num_nodes(\"concept\")\n",
    "\n",
    "    s1 = 0.7\n",
    "    s2 = 0.8\n",
    "\n",
    "    train_idx = {\n",
    "        \"event\": torch.tensor(range(0, int(nEvents * s1))).to(train_args[\"device\"]),\n",
    "        \"concept\": torch.tensor(range(0, int(nConcepts * s1))).to(train_args[\"device\"]),\n",
    "    }\n",
    "    val_idx = {\n",
    "        \"event\": torch.tensor(range(int(nEvents * s1), int(nEvents * s2))).to(\n",
    "            train_args[\"device\"]\n",
    "        ),\n",
    "        \"concept\": torch.tensor(range(int(nConcepts * s1), int(nConcepts * s2))).to(\n",
    "            train_args[\"device\"]\n",
    "        ),\n",
    "    }\n",
    "    test_idx = {\n",
    "        \"event\": torch.tensor(range(int(nEvents * s2), nEvents)).to(\n",
    "            train_args[\"device\"]\n",
    "        ),\n",
    "        \"concept\": torch.tensor(range(int(nConcepts * s2), nConcepts)).to(\n",
    "            train_args[\"device\"]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return [train_idx, val_idx, test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hetero_graph):\n",
    "    best_model = None\n",
    "    best_tvt_scores = (\n",
    "        (float(\"inf\"), float(\"inf\")),\n",
    "        (float(\"inf\"), float(\"inf\")),\n",
    "        (float(\"inf\"), float(\"inf\")),\n",
    "    )\n",
    "\n",
    "    model = HeteroGNN(\n",
    "        hetero_graph,\n",
    "        train_args,\n",
    "        num_layers=train_args[\"num_layers\"],\n",
    "        aggr=train_args[\"aggr\"],\n",
    "        return_embedding=True,\n",
    "    ).to(train_args[\"device\"])\n",
    "\n",
    "    train_idx, val_idx, test_idx = create_split(hetero_graph)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=train_args[\"lr\"], weight_decay=train_args[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    for epoch in range(train_args[\"epochs\"]):\n",
    "        # Train\n",
    "        loss = train(model, optimizer, hetero_graph, train_idx)\n",
    "        # Test for the accuracy of the model\n",
    "        cur_tvt_scores, best_tvt_scores, best_model = test(\n",
    "            model,\n",
    "            hetero_graph,\n",
    "            [train_idx, val_idx, test_idx],\n",
    "            best_model,\n",
    "            best_tvt_scores,\n",
    "        )\n",
    "        print(\n",
    "            f\"\"\"Epoch: {epoch} Loss: {loss:.4f}\n",
    "            Train: Abs={cur_tvt_scores[0][0].item():.4f} Rel={cur_tvt_scores[0][1].item():.4f}\n",
    "            Val: Abs={cur_tvt_scores[1][0].item():.4f} Rel={cur_tvt_scores[1][1].item():.4f}\n",
    "            Test: Abs={cur_tvt_scores[2][0].item():.4f} Rel={cur_tvt_scores[2][1].item():.4f}\"\"\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Best model\n",
    "            Train: Abs={best_tvt_scores[0][0].item():.4f} Rel={best_tvt_scores[0][1].item():.4f}\n",
    "            Val: Abs={best_tvt_scores[1][0].item():.4f} Rel={best_tvt_scores[1][1].item():.4f}\n",
    "            Test: Abs={best_tvt_scores[2][0].item():.4f} Rel={best_tvt_scores[2][1].item():.4f}\"\"\"\n",
    "    )\n",
    "\n",
    "    model = HeteroGNN(\n",
    "        hetero_graph,\n",
    "        train_args,\n",
    "        num_layers=train_args[\"num_layers\"],\n",
    "        aggr=train_args[\"aggr\"],\n",
    "    ).to(train_args[\"device\"])\n",
    "\n",
    "    model.load_state_dict(torch.load(\"./best_model.pkl\"))\n",
    "\n",
    "    preds = model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
    "\n",
    "    cur_tvt_scores, best_tvt_scores, best_model = test(\n",
    "        model, hetero_graph, [train_idx, val_idx, test_idx], best_model, best_tvt_scores\n",
    "    )\n",
    "\n",
    "    display_predictions(preds, hetero_graph, test_idx)\n",
    "\n",
    "\n",
    "def display_predictions(preds, hetero_graph, test_idx):\n",
    "    for i in range(test_idx[\"event\"].shape[0]):\n",
    "        if hetero_graph.node_target[\"event\"][test_idx[\"event\"]][i] != -1:\n",
    "            print(\n",
    "                i,\n",
    "                preds[\"event\"][test_idx[\"event\"]][i],\n",
    "                hetero_graph.node_target[\"event\"][test_idx[\"event\"]][i],\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
