{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import deepsnap\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
    "        super(HeteroGNNConv, self).__init__(aggr=\"mean\")\n",
    "\n",
    "        self.in_channels_src = in_channels_src\n",
    "        self.in_channels_dst = in_channels_dst\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.lin_dst = None\n",
    "        self.lin_src = None\n",
    "\n",
    "        self.lin_update = None\n",
    "\n",
    "        self.lin_dst = nn.Linear(in_channels_dst, out_channels)\n",
    "        self.lin_src = nn.Linear(in_channels_src, out_channels)\n",
    "        self.lin_update = nn.Linear(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_feature_src,\n",
    "        node_feature_dst,\n",
    "        edge_index,\n",
    "        size=None,\n",
    "        res_n_id=None,\n",
    "        ):\n",
    "\n",
    "        return self.propagate(edge_index, node_feature_src=node_feature_src, \n",
    "                    node_feature_dst=node_feature_dst, size=size, res_n_id=res_n_id)\n",
    "\n",
    "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
    "\n",
    "        out = matmul(edge_index, node_feature_src, reduce='mean')\n",
    "\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out, node_feature_dst, res_n_id):\n",
    "\n",
    "        dst_out = self.lin_dst(node_feature_dst)\n",
    "        aggr_out = self.lin_src(aggr_out)\n",
    "        aggr_out = torch.cat([dst_out, aggr_out], -1)\n",
    "        aggr_out = self.lin_update(aggr_out)\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
    "    def __init__(self, convs, args, aggr=\"mean\"):\n",
    "        \"\"\"\n",
    "        Initializes the HeteroGNNWrapperConv instance.\n",
    "\n",
    "        :param convs: Dictionary of convolution layers for each message type.\n",
    "        :param args: Arguments dictionary containing hyperparameters like hidden_size and attn_size.\n",
    "        :param aggr: Aggregation method, defaults to 'mean'.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(HeteroGNNWrapperConv, self).__init__(convs, None)\n",
    "        self.aggr = aggr\n",
    "\n",
    "        # Map the index and message type\n",
    "        self.mapping = {}\n",
    "\n",
    "        # A numpy array that stores the final attention probability\n",
    "        self.alpha = None\n",
    "\n",
    "        self.attn_proj = None\n",
    "\n",
    "        if self.aggr == \"attn\":\n",
    "\n",
    "            self.attn_proj = nn.Sequential(\n",
    "                nn.Linear(args['hidden_size'], args['attn_size']),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(args['attn_size'], 1, bias=False)\n",
    "            )\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        super(HeteroGNNWrapperConv, self).reset_parameters()\n",
    "        if self.aggr == \"attn\":\n",
    "            for layer in self.attn_proj.children():\n",
    "                layer.reset_parameters()\n",
    "    \n",
    "    def forward(self, node_features, edge_indices):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        :param node_features: Dictionary of node features for each node type.\n",
    "        :param edge_indices: Dictionary of edge indices for each message type.\n",
    "        :return: Aggregated node embeddings for each node type.\n",
    "        \"\"\"\n",
    "        \n",
    "        message_type_emb = {}\n",
    "        for message_key, message_type in edge_indices.items():\n",
    "            src_type, edge_type, dst_type = message_key\n",
    "            node_feature_src = node_features[src_type]\n",
    "            node_feature_dst = node_features[dst_type]\n",
    "            edge_index = edge_indices[message_key]\n",
    "            message_type_emb[message_key] = (\n",
    "                self.convs[message_key](\n",
    "                    node_feature_src,\n",
    "                    node_feature_dst,\n",
    "                    edge_index,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        \n",
    "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()}\n",
    "        mapping = {}        \n",
    "        \n",
    "        for (src, edge_type, dst), item in message_type_emb.items():\n",
    "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
    "            node_emb[dst].append(item)\n",
    "        self.mapping = mapping\n",
    "        \n",
    "        for node_type, embs in node_emb.items():\n",
    "            if len(embs) == 1:\n",
    "                node_emb[node_type] = embs[0]\n",
    "            else:\n",
    "                node_emb[node_type] = self.aggregate(embs)\n",
    "                \n",
    "        return node_emb\n",
    "    \n",
    "    def aggregate(self, xs):\n",
    "        \"\"\"\n",
    "        Aggregates node embeddings using the specified aggregation method.\n",
    "\n",
    "        :param xs: List of node embeddings to aggregate.\n",
    "        :return: Aggregated node embeddings as a torch.Tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.aggr == \"mean\":\n",
    "            xs = torch.stack(xs)\n",
    "            out = torch.mean(xs, dim=0)\n",
    "            return out\n",
    "\n",
    "        elif self.aggr == \"attn\":\n",
    "            xs = torch.stack(xs, dim=0)\n",
    "            s = self.attn_proj(xs).squeeze(-1)\n",
    "            s = torch.mean(s, dim=-1)\n",
    "            self.alpha = torch.softmax(s, dim=0).detach()\n",
    "            out = self.alpha.reshape(-1, 1, 1) * xs\n",
    "            out = torch.sum(out, dim=0)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates convolutional layers for each message type in a heterogeneous graph.\n",
    "\n",
    "    :param hetero_graph: The heterogeneous graph for which convolutions are to be created.\n",
    "    :param conv: The convolutional layer class or constructor.\n",
    "    :param hidden_size: The number of features in the hidden layer.\n",
    "    :param first_layer: Boolean indicating if this is the first layer in the network.\n",
    "    \n",
    "    :return: A dictionary of convolutional layers, keyed by message type.\n",
    "    \"\"\"\n",
    "\n",
    "    convs = {}\n",
    "    \n",
    "    # Extracting all types of messages/edges in the heterogeneous graph.\n",
    "    all_messages_types = hetero_graph.message_types\n",
    "    for message_type in all_messages_types:\n",
    "        \n",
    "        # Determine the input feature size for source and destination nodes.\n",
    "        # If it's the first layer, use the feature size of the nodes.\n",
    "        # Otherwise, use the hidden size, since from there on the size of embeddings\n",
    "        # is the same for all nodes.\n",
    "        if first_layer:\n",
    "            in_channels_src = hetero_graph.num_node_features(message_type[0])\n",
    "            in_channels_dst = hetero_graph.num_node_features(message_type[2])\n",
    "        else:\n",
    "            in_channels_src = hidden_size\n",
    "            in_channels_dst = hidden_size\n",
    "        out_channels = hidden_size\n",
    "        \n",
    "        # Create a convolutional layer for this message type and add it to the dictionary.\n",
    "        convs[message_type] = conv(in_channels_src, in_channels_dst, out_channels)\n",
    "    \n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hetero_graph, args, num_layers, aggr=\"mean\"):\n",
    "        super(HeteroGNN, self).__init__()\n",
    "\n",
    "        self.aggr = aggr\n",
    "        self.hidden_size = args['hidden_size']\n",
    "\n",
    "        self.bns1 = nn.ModuleDict()\n",
    "        self.bns2 = nn.ModuleDict()\n",
    "        self.relus1 = nn.ModuleDict()\n",
    "        self.relus2 = nn.ModuleDict()\n",
    "        self.post_mps = nn.ModuleDict()\n",
    "        self.fc = nn.ModuleDict()\n",
    "        \n",
    "        # Initialize the graph convolutional layers\n",
    "        self.convs1 = HeteroGNNWrapperConv(\n",
    "            generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=True), \n",
    "            args, self.aggr)\n",
    "        self.convs2 = HeteroGNNWrapperConv(\n",
    "            generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=False), \n",
    "            args, self.aggr)\n",
    "\n",
    "        # Initialize batch normalization, ReLU, and fully connected layers for each node type\n",
    "        all_node_types = hetero_graph.node_types\n",
    "        for node_type in all_node_types:\n",
    "            \n",
    "            self.bns1[node_type] = nn.BatchNorm1d(self.hidden_size, eps=1.0)\n",
    "            self.bns2[node_type] = nn.BatchNorm1d(self.hidden_size, eps=1.0)\n",
    "            \n",
    "            self.relus1[node_type] = nn.LeakyReLU()\n",
    "            self.relus2[node_type] = nn.LeakyReLU()\n",
    "            self.fc[node_type] = nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "    def forward(self, node_feature, edge_index):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        :param node_feature: Dictionary of node features for each node type.\n",
    "        :param edge_index: Dictionary of edge indices for each message type.\n",
    "        :return: The output embeddings for each node type after passing through the model.\n",
    "        \"\"\"\n",
    "        x = node_feature\n",
    "\n",
    "        # Apply graph convolutional, batch normalization, and ReLU layers\n",
    "        x = self.convs1(x, edge_index)\n",
    "        x = forward_op(x, self.bns1)\n",
    "        x = forward_op(x, self.relus1)\n",
    "\n",
    "        x = self.convs2(x, edge_index)\n",
    "        x = forward_op(x, self.bns2)\n",
    "        x = forward_op(x, self.relus2)\n",
    "        \n",
    "        x = forward_op(x, self.fc)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, preds, y, indices):\n",
    "        \"\"\"\n",
    "        Computes the loss for the model.\n",
    "\n",
    "        :param preds: Predictions made by the model.\n",
    "        :param y: Ground truth target values.\n",
    "        :param indices: Indices of nodes for which loss should be calculated.\n",
    "        \n",
    "        :return: The computed loss value.\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = 0\n",
    "        loss_func = torch.nn.MSELoss() \n",
    "             \n",
    "        mask = y['event'][indices['event'], 0] != -1\n",
    "        non_zero_idx = torch.masked_select(indices['event'], mask)\n",
    "                \n",
    "        loss += loss_func(preds['event'][non_zero_idx], y['event'][non_zero_idx])\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, hetero_graph, train_idx):\n",
    "    \"\"\"\n",
    "    Trains the model on the given heterogeneous graph using the specified indices.\n",
    "\n",
    "    :param model: The graph neural network model to train.\n",
    "    :param optimizer: The optimizer used for training the model.\n",
    "    :param hetero_graph: The heterogeneous graph data.\n",
    "    :param train_idx: Indices for training nodes.\n",
    "\n",
    "    :return: The training loss as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train() # Set the model to training mode\n",
    "    optimizer.zero_grad() # Zero out any existing gradients \n",
    "    \n",
    "    # Compute predictions using the model\n",
    "    preds = model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
    "\n",
    "    # Compute the loss using model's loss function\n",
    "    loss = model.loss(preds, hetero_graph.node_target, train_idx)\n",
    "\n",
    "    loss.backward() # Backward pass: compute gradient of the loss\n",
    "    optimizer.step() # Perform a single optimization step, updates parameters\n",
    "    \n",
    "    return loss.item() \n",
    "\n",
    "def test(model, graph, indices, best_model=None, best_val=0):\n",
    "    \"\"\"\n",
    "    Tests the model on given indices and updates the best model based on validation loss.\n",
    "\n",
    "    :param model: The trained graph neural network model.\n",
    "    :param graph: The heterogeneous graph data.\n",
    "    :param indices: List of indices for training, validation, and testing nodes.\n",
    "    :param best_model: The current best model based on validation loss.\n",
    "    :param best_val: The current best validation loss.\n",
    "    \n",
    "    :return: A tuple containing the list of losses for each dataset, the best model, and the best validation loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    accs = []\n",
    "    \n",
    "    # Evaluate the model on each set of indices\n",
    "    for index in indices:\n",
    "        preds = model(graph.node_feature, graph.edge_index)\n",
    "        \n",
    "        idx = index['event']\n",
    "\n",
    "        L1 = torch.sum(torch.abs(preds['event'][idx] - graph.node_target['event'][idx]))\n",
    "        \n",
    "        accs.append(L1)\n",
    "    \n",
    "    # Update the best model and validation loss if the current model performs better\n",
    "    if accs[1] < best_val:\n",
    "        best_val = accs[1]\n",
    "        best_model = copy.deepcopy(model)\n",
    "    \n",
    "    return accs, best_model, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'hidden_size': 64,\n",
    "    'epochs': 200,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.201,\n",
    "    'attn_size': 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell creates a small heterogeneous graph, primarily for testing purposes.\n",
    "\"\"\"\n",
    "\n",
    "S_node_feature = {\n",
    "    \"event\": torch.tensor([\n",
    "                [1, 1, 1],   # event 0\n",
    "                [2, 2, 2]    # event 1\n",
    "    ], dtype=torch.float32),\n",
    "    \"concept\": torch.tensor([\n",
    "                [2, 2, 2],   # concept 0\n",
    "                [3, 3, 3]    # concept 1\n",
    "    ], dtype=torch.float32)\n",
    "}\n",
    "\n",
    "# S_node_label = {\n",
    "#     \"event\": torch.tensor([0, 1], dtype=torch.long), # Class 0, Class 1\n",
    "#     \"concept\": torch.tensor([0, 1], dtype=torch.long)  # Class 0, Class 1\n",
    "# }\n",
    "\n",
    "S_node_targets = {\n",
    "    \"event\": torch.tensor([[50], [2000]], dtype=torch.float32),\n",
    "    # \"concept\": torch.tensor([[0], [0]], dtype=torch.float32)\n",
    "}\n",
    "\n",
    "S_edge_index = {\n",
    "    (\"event\", \"similar\", \"event\"): torch.tensor([[0,1],[1,0]], dtype=torch.int64),\n",
    "    (\"event\", \"related\", \"concept\"): torch.tensor([[0,1],[0,1]], dtype=torch.int64),\n",
    "    (\"concept\", \"related\", \"event\"): torch.tensor([[0,1],[0,1]], dtype=torch.int64)\n",
    "}\n",
    "\n",
    "# Testing\n",
    "hetero_graph = HeteroGraph(\n",
    "    node_feature=S_node_feature,\n",
    "    node_target=S_node_targets,\n",
    "    edge_index=S_edge_index\n",
    ")\n",
    "\n",
    "train_idx = {\"event\": torch.tensor([0, 1]).to(args['device']), \"concept\": torch.tensor([0, 1]).to(args['device'])}\n",
    "val_idx = {\"event\": torch.tensor([0, 1]).to(args['device']), \"concept\": torch.tensor([0, 1]).to(args['device'])}\n",
    "test_idx = {\"event\": torch.tensor([0, 1]).to(args['device']), \"concept\": torch.tensor([0, 1]).to(args['device'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./10_concepts_similar_llm_noUnknown_CHEAT.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "    # Convert to directed graph for compatibility with Deepsnap\n",
    "    # G = G.to_directed()\n",
    "    \n",
    "hetero_graph = HeteroGraph(G, netlib=nx, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE ('concept', 'related', 'event')\n",
      "\t Feature 1\n",
      "\t Feature 770\n",
      "TYPE ('event', 'related', 'concept')\n",
      "\t Feature 770\n",
      "\t Feature 1\n",
      "TYPE ('event', 'similar', 'event')\n",
      "\t Feature 770\n",
      "\t Feature 770\n",
      "KEY ('concept', 'related', 'event') <class 'tuple'>\n",
      "KEY NUMS ('concept', 'related', 'event') 36989 5000\n",
      "MAX EDGES tensor(36988) tensor(4999) 36989 5000\n",
      "KEY ('event', 'related', 'concept') <class 'tuple'>\n",
      "KEY NUMS ('event', 'related', 'concept') 5000 36989\n",
      "MAX EDGES tensor(4999) tensor(36988) 5000 36989\n",
      "KEY ('event', 'similar', 'event') <class 'tuple'>\n",
      "KEY NUMS ('event', 'similar', 'event') 5000 5000\n",
      "MAX EDGES tensor(4986) tensor(4986) 5000 5000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HeteroGraph' object has no attribute 'node_target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Adrian\\AI Lab Dropbox\\Adrian Mladenić Grobelnik\\Areas\\Uni\\MLG\\MLG-Predicting-Impacful-Events\\Heterogeneus\\Regression.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adrian/AI%20Lab%20Dropbox/Adrian%20Mladeni%C4%87%20Grobelnik/Areas/Uni/MLG/MLG-Predicting-Impacful-Events/Heterogeneus/Regression.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     hetero_graph\u001b[39m.\u001b[39medge_index[key] \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mt()\u001b[39m.\u001b[39mto(args[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adrian/AI%20Lab%20Dropbox/Adrian%20Mladeni%C4%87%20Grobelnik/Areas/Uni/MLG/MLG-Predicting-Impacful-Events/Heterogeneus/Regression.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Send node targets to device\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Adrian/AI%20Lab%20Dropbox/Adrian%20Mladeni%C4%87%20Grobelnik/Areas/Uni/MLG/MLG-Predicting-Impacful-Events/Heterogeneus/Regression.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m hetero_graph\u001b[39m.\u001b[39;49mnode_target:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adrian/AI%20Lab%20Dropbox/Adrian%20Mladeni%C4%87%20Grobelnik/Areas/Uni/MLG/MLG-Predicting-Impacful-Events/Heterogeneus/Regression.ipynb#X30sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     hetero_graph\u001b[39m.\u001b[39mnode_target[key] \u001b[39m=\u001b[39m hetero_graph\u001b[39m.\u001b[39mnode_target[key]\u001b[39m.\u001b[39mto(args[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HeteroGraph' object has no attribute 'node_target'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code block ensures that all tensors in a heterogeneous graph are transferred to the same \n",
    "computational device, as specified in the 'args' dictionary.\n",
    "\"\"\"\n",
    "\n",
    "for message_type in hetero_graph.message_types:\n",
    "    print(\"TYPE\", message_type)\n",
    "    print(\"\\t Feature\", hetero_graph.num_node_features(message_type[0]))\n",
    "    print(\"\\t Feature\", hetero_graph.num_node_features(message_type[2]))\n",
    "\n",
    "# Send node features to device\n",
    "for key in hetero_graph.node_feature:\n",
    "    hetero_graph.node_feature[key] = hetero_graph.node_feature[key].to(args['device'])\n",
    "\n",
    "# for key in hetero_graph.node_label:\n",
    "#     hetero_graph.node_label[key] = hetero_graph.node_label[key].to(args['device'])\n",
    "\n",
    "# Create a torch.SparseTensor from edge_index and send it to device\n",
    "for key in hetero_graph.edge_index:\n",
    "    print(\"KEY\", key, type(key))\n",
    "    print(\"KEY NUMS\", key, hetero_graph.num_nodes(key[0]), hetero_graph.num_nodes(key[2]))\n",
    "    \n",
    "    edge_index = hetero_graph.edge_index[key]\n",
    "\n",
    "    print(\"MAX EDGES\", edge_index[0].max(), edge_index[1].max(), hetero_graph.num_nodes(key[0]), hetero_graph.num_nodes(key[2]))\n",
    "    adj = SparseTensor(row=edge_index[0].long(), col=edge_index[1].long(), sparse_sizes=(hetero_graph.num_nodes(key[0]), hetero_graph.num_nodes(key[2])))\n",
    "    hetero_graph.edge_index[key] = adj.t().to(args['device'])\n",
    "    \n",
    "# Send node targets to device\n",
    "for key in hetero_graph.node_target:\n",
    "    hetero_graph.node_target[key] = hetero_graph.node_target[key].to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code block creates a basic split of a graph's nodes into training, validation, and testing sets. \n",
    "It uses predefined ratios to divide 'event' and 'concept' nodes in the heterogeneous graph for a simple \n",
    "dataset split, mainly for testing purposes.\n",
    "\"\"\"\n",
    "\n",
    "nEvents = hetero_graph.num_nodes(\"event\")\n",
    "nConcepts = hetero_graph.num_nodes(\"concept\")\n",
    "\n",
    "s1 = 0.7\n",
    "s2 = 0.8\n",
    "\n",
    "train_idx = {   \"event\": torch.tensor(range(0, int(nEvents * s1))).to(args[\"device\"]), \n",
    "                \"concept\": torch.tensor(range(0, int(nConcepts * s1))).to(args[\"device\"])\n",
    "            }\n",
    "val_idx = {   \"event\": torch.tensor(range(int(nEvents * s1), int(nEvents * s2))).to(args[\"device\"]), \n",
    "                \"concept\": torch.tensor(range(int(nConcepts * s1), int(nConcepts * s2))).to(args[\"device\"])\n",
    "            }\n",
    "test_idx = {   \"event\": torch.tensor(range(int(nEvents * s2), nEvents)).to(args[\"device\"]), \n",
    "                \"concept\": torch.tensor(range(int(nConcepts * s2), nConcepts)).to(args[\"device\"])\n",
    "            }\n",
    "\n",
    "print(train_idx[\"event\"].shape)\n",
    "print(test_idx[\"event\"].shape)\n",
    "print(val_idx[\"event\"].shape)\n",
    "\n",
    "\n",
    "# TODO: Add node labels to the nodes and try to make the deepsnap split work even for regression!\n",
    "\n",
    "# dataset = deepsnap.dataset.GraphDataset([hetero_graph], task='node')\n",
    "\n",
    "# dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.4, 0.3, 0.3])\n",
    "# datasets = {'train': dataset_train, 'val': dataset_val, 'test': dataset_test}\n",
    "\n",
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a HeteroGNN model from the previously constructed hetero graph and trains it.\n",
    "\"\"\"\n",
    "\n",
    "best_model = None\n",
    "best_val = float(\"inf\")\n",
    "\n",
    "model = HeteroGNN(hetero_graph, args, num_layers=2, aggr=\"mean\").to(args['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "for epoch in range(args['epochs']):\n",
    "    # Train\n",
    "    loss = train(model, optimizer, hetero_graph, train_idx)\n",
    "    # Test for the accuracy of the model\n",
    "    accs, best_model, best_val = test(model, hetero_graph, [train_idx, val_idx, test_idx], best_model, best_val)\n",
    "    print(f\"Epoch {epoch} Loss {loss} Accs {accs}\")\n",
    "\n",
    "# Get the accuracy of the best model\n",
    "best_accs, _, _ = test(best_model, hetero_graph, [train_idx, val_idx, test_idx])\n",
    "\n",
    "print(\"Best accs\", best_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
    "# mask = preds['event'] > 0\n",
    "# preds['event'][preds['event'] > 0].shape\n",
    "\n",
    "# print(preds['event'][0], hetero_graph.node_target['event'][0]) \n",
    "\n",
    "\n",
    "#print(hetero_graph.node_feature['event'])\n",
    "\n",
    "# for i in range(3000):\n",
    "#     if hetero_graph.node_target['event'][i] != -1: # concepts have node target -1\n",
    "#         print(preds['event'][i], hetero_graph.node_target['event'][i])\n",
    "        \n",
    "    \n",
    "for i in range(1000):    \n",
    "    if hetero_graph.node_target['event'][test_idx['event']][i] != -1:\n",
    "        print(preds['event'][test_idx['event']][i], hetero_graph.node_target['event'][test_idx['event']][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
