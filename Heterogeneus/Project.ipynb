{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import deepsnap\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
    "        super(HeteroGNNConv, self).__init__(aggr=\"mean\")\n",
    "\n",
    "        self.in_channels_src = in_channels_src\n",
    "        self.in_channels_dst = in_channels_dst\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # To simplify implementation, please initialize both self.lin_dst\n",
    "        # and self.lin_src out_features to out_channels\n",
    "        self.lin_dst = None\n",
    "        self.lin_src = None\n",
    "\n",
    "        self.lin_update = None\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~3 lines of code)\n",
    "\n",
    "        self.lin_dst = nn.Linear(self.in_channels_src, self.out_channels)\n",
    "        self.lin_src = nn.Linear(self.in_channels_dst, self.out_channels)\n",
    "        self.lin_update = nn.Linear(2*self.out_channels, self.out_channels)\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_feature_src,\n",
    "        node_feature_dst,\n",
    "        edge_index,\n",
    "        size=None,\n",
    "        res_n_id=None,\n",
    "    ):\n",
    "        ############# Your code here #############\n",
    "        ## (~1 line of code)\n",
    "\n",
    "        return self.propagate(edge_index, node_feature_src=node_feature_src, \n",
    "                    node_feature_dst=node_feature_dst, size=size, res_n_id=res_n_id)\n",
    "        ##########################################\n",
    "\n",
    "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~1 line of code)\n",
    "        ## Note:\n",
    "        ## 1. Different from what we implemented in Colab 3, we use message_and_aggregate\n",
    "        ## to replace the message and aggregate. The benefit is that we can avoid\n",
    "        ## materializing x_i and x_j, and make the implementation more efficient.\n",
    "        ## 2. To implement efficiently, following PyG documentation is helpful:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "        ## 3. Here edge_index is torch_sparse SparseTensor.\n",
    "\n",
    "        out = matmul(edge_index, node_feature_src, reduce='mean')\n",
    "        ##########################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out, node_feature_dst, res_n_id):\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~4 lines of code)\n",
    "        dst_out = self.lin_dst(node_feature_dst)\n",
    "        aggr_out = self.lin_src(aggr_out)\n",
    "        # print(aggr_out.shape, dst_out.shape)\n",
    "        aggr_out = torch.cat([dst_out, aggr_out], -1)\n",
    "        # print(aggr_out.shape, )\n",
    "        aggr_out = self.lin_update(aggr_out)\n",
    "        ##########################################\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
    "    def __init__(self, convs, args, aggr=\"mean\"):\n",
    "        super(HeteroGNNWrapperConv, self).__init__(convs, None)\n",
    "        self.aggr = aggr\n",
    "\n",
    "        # Map the index and message type\n",
    "        self.mapping = {}\n",
    "\n",
    "        # A numpy array that stores the final attention probability\n",
    "        self.alpha = None\n",
    "\n",
    "        self.attn_proj = None\n",
    "\n",
    "        if self.aggr == \"attn\":\n",
    "            ############# Your code here #############\n",
    "            ## (~1 line of code)\n",
    "            ## Note:\n",
    "            ## 1. Initialize self.attn_proj here.\n",
    "            ## 2. You should use nn.Sequential for self.attn_proj\n",
    "            ## 3. nn.Linear and nn.Tanh are useful.\n",
    "            ## 4. You can create a vector parameter by using:\n",
    "            ## nn.Linear(some_size, 1, bias=False)\n",
    "            ## 5. The first linear layer should have out_features as args['attn_size']\n",
    "            ## 6. You can assume we only have one \"head\" for the attention.\n",
    "            ## 7. We recommend you to implement the mean aggregation first. After \n",
    "            ## the mean aggregation works well in the training, then you can \n",
    "            ## implement this part.\n",
    "\n",
    "            self.attn_proj = nn.Sequential(\n",
    "                nn.Linear(args['hidden_size'], args['attn_size']),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(args['attn_size'], 1, bias=False)\n",
    "            )\n",
    "            #########################################\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        super(HeteroGNNWrapperConv, self).reset_parameters()\n",
    "        if self.aggr == \"attn\":\n",
    "            for layer in self.attn_proj.children():\n",
    "                layer.reset_parameters()\n",
    "    \n",
    "    def forward(self, node_features, edge_indices):\n",
    "        message_type_emb = {}\n",
    "        for message_key, message_type in edge_indices.items():\n",
    "            src_type, edge_type, dst_type = message_key\n",
    "            node_feature_src = node_features[src_type]\n",
    "            node_feature_dst = node_features[dst_type]\n",
    "            edge_index = edge_indices[message_key]\n",
    "            message_type_emb[message_key] = (\n",
    "                self.convs[message_key](\n",
    "                    node_feature_src,\n",
    "                    node_feature_dst,\n",
    "                    edge_index,\n",
    "                )\n",
    "            )\n",
    "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()}\n",
    "        mapping = {}        \n",
    "        for (src, edge_type, dst), item in message_type_emb.items():\n",
    "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
    "            node_emb[dst].append(item)\n",
    "        self.mapping = mapping\n",
    "        for node_type, embs in node_emb.items():\n",
    "            if len(embs) == 1:\n",
    "                node_emb[node_type] = embs[0]\n",
    "            else:\n",
    "                node_emb[node_type] = self.aggregate(embs)\n",
    "        return node_emb\n",
    "    \n",
    "    def aggregate(self, xs):\n",
    "        # TODO: Implement this function that aggregates all message type results.\n",
    "        # Here, xs is a list of tensors (embeddings) with respect to message \n",
    "        # type aggregation results.\n",
    "\n",
    "        if self.aggr == \"mean\":\n",
    "\n",
    "            ############# Your code here #############\n",
    "            ## (~2 lines of code)\n",
    "            xs = torch.stack(xs)\n",
    "            out = torch.mean(xs, dim=0)\n",
    "            return out\n",
    "            ##########################################\n",
    "\n",
    "        elif self.aggr == \"attn\":\n",
    "\n",
    "            ############# Your code here #############\n",
    "            ## (~10 lines of code)\n",
    "            ## Note:\n",
    "            ## 1. Store the value of attention alpha (as a numpy array) to self.alpha,\n",
    "            ## which has the shape (len(xs), ) self.alpha will be not be used \n",
    "            ## to backpropagate etc. in the model. We will use it to see how much \n",
    "            ## attention the layer pays on different message types.\n",
    "            ## 2. torch.softmax and torch.cat are useful.\n",
    "            ## 3. You might need to reshape the tensors by using the \n",
    "            ## `view()` function https://pytorch.org/docs/stable/tensor_view.html\n",
    "            xs = torch.stack(xs, dim=0)\n",
    "            s = self.attn_proj(xs).squeeze(-1)\n",
    "            s = torch.mean(s, dim=-1)\n",
    "            self.alpha = torch.softmax(s, dim=0).detach()\n",
    "            out = self.alpha.reshape(-1, 1, 1) * xs\n",
    "            out = torch.sum(out, dim=0)\n",
    "            return out\n",
    "            ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
    "    # TODO: Implement this function that returns a dictionary of `HeteroGNNConv` \n",
    "    # layers where the keys are message types. `hetero_graph` is deepsnap `HeteroGraph`\n",
    "    # object and the `conv` is the `HeteroGNNConv`.\n",
    "\n",
    "    convs = {}\n",
    "\n",
    "    ############# Your code here #############\n",
    "    ## (~9 lines of code)\n",
    "\n",
    "    all_messages_types = hetero_graph.message_types\n",
    "    for message_type in all_messages_types:\n",
    "        if first_layer:\n",
    "            in_channels_src = hetero_graph.num_node_features(message_type[0])\n",
    "            in_channels_dst = hetero_graph.num_node_features(message_type[2])\n",
    "        else:\n",
    "            in_channels_src = hidden_size\n",
    "            in_channels_dst = hidden_size\n",
    "        out_channels = hidden_size\n",
    "        convs[message_type] = conv(in_channels_src, in_channels_dst, out_channels)\n",
    "    ##########################################\n",
    "    \n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hetero_graph, args, aggr=\"mean\"):\n",
    "        super(HeteroGNN, self).__init__()\n",
    "\n",
    "        self.aggr = aggr\n",
    "        self.hidden_size = args['hidden_size']\n",
    "\n",
    "        self.convs1 = None\n",
    "        self.convs2 = None\n",
    "\n",
    "        self.bns1 = nn.ModuleDict()\n",
    "        self.bns2 = nn.ModuleDict()\n",
    "        self.relus1 = nn.ModuleDict()\n",
    "        self.relus2 = nn.ModuleDict()\n",
    "        self.post_mps = nn.ModuleDict()\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~10 lines of code)\n",
    "        ## Note:\n",
    "        ## 1. For self.convs1 and self.convs2, call generate_convs at first and then\n",
    "        ## pass the returned dictionary of `HeteroGNNConv` to `HeteroGNNWrapperConv`.\n",
    "        ## 2. For self.bns, self.relus and self.post_mps, the keys are node_types.\n",
    "        ## `deepsnap.hetero_graph.HeteroGraph.node_types` will be helpful.\n",
    "        ## 3. Initialize all batchnorms to torch.nn.BatchNorm1d(hidden_size, eps=1.0).\n",
    "        ## 4. Initialize all relus to nn.LeakyReLU().\n",
    "        ## 5. For self.post_mps, each value in the ModuleDict is a linear layer \n",
    "        ## where the `out_features` is the number of classes for that node type.\n",
    "        ## `deepsnap.hetero_graph.HeteroGraph.num_node_labels(node_type)` will be\n",
    "        ## useful.\n",
    "\n",
    "        self.convs1 = HeteroGNNWrapperConv(\n",
    "            generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=True), \n",
    "            args, self.aggr)\n",
    "        self.convs2 = HeteroGNNWrapperConv(\n",
    "            generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=False), \n",
    "            args, self.aggr)\n",
    "\n",
    "        all_node_types = hetero_graph.node_types\n",
    "        for node_type in all_node_types:\n",
    "            self.bns1[node_type] = nn.BatchNorm1d(self.hidden_size, eps=1.0)\n",
    "            self.bns2[node_type] = nn.BatchNorm1d(self.hidden_size, eps=1.0)\n",
    "            self.relus1[node_type] = nn.LeakyReLU()\n",
    "            self.relus2[node_type] = nn.LeakyReLU()\n",
    "            self.post_mps[node_type] = nn.Linear(self.hidden_size, hetero_graph.num_node_labels(node_type))\n",
    "\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "    def forward(self, node_feature, edge_index):\n",
    "        # TODO: Implement the forward function. Notice that `node_feature` is \n",
    "        # a dictionary of tensors where keys are node types and values are \n",
    "        # corresponding feature tensors. The `edge_index` is a dictionary of \n",
    "        # tensors where keys are message types and values are corresponding\n",
    "        # edge index tensors (with respect to each message type).\n",
    "\n",
    "        x = node_feature\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~7 lines of code)\n",
    "        ## Note:\n",
    "        ## 1. `deepsnap.hetero_gnn.forward_op` can be helpful.\n",
    "        x = self.convs1(x, edge_index)\n",
    "        x = forward_op(x, self.bns1)\n",
    "        x = forward_op(x, self.relus1)\n",
    "        x = self.convs2(x, edge_index)\n",
    "        x = forward_op(x, self.bns2)\n",
    "        x = forward_op(x, self.relus2)\n",
    "        x = forward_op(x, self.post_mps)\n",
    "        ##########################################\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def loss(self, preds, y, indices):\n",
    "        \n",
    "        loss = 0\n",
    "        loss_func = F.cross_entropy\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~3 lines of code)\n",
    "        ## Note:\n",
    "        ## 1. For each node type in preds, accumulate computed loss to `loss`\n",
    "        ## 2. Loss need to be computed with respect to the given index\n",
    "\n",
    "        for node_type in preds:\n",
    "            idx = indices[node_type]\n",
    "            loss += loss_func(preds[node_type][idx], y[node_type][idx])\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, hetero_graph, train_idx):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
    "\n",
    "    loss = None\n",
    "\n",
    "    ############# Your code here #############\n",
    "    ## Note:\n",
    "    ## 1. `deepsnap.hetero_graph.HeteroGraph.node_label` is useful\n",
    "    ## 2. Compute the loss here\n",
    "    \n",
    "    loss = model.loss(preds, hetero_graph.node_label, train_idx)\n",
    "    ##########################################\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, graph, indices, best_model=None, best_val=0):\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    for index in indices:\n",
    "        preds = model(graph.node_feature, graph.edge_index)\n",
    "        num_node_types = 0\n",
    "        micro = 0\n",
    "        macro = 0\n",
    "        for node_type in preds:\n",
    "            idx = index[node_type]\n",
    "            pred = preds[node_type][idx]\n",
    "            pred = pred.max(1)[1]\n",
    "            label_np = graph.node_label[node_type][idx].cpu().numpy()\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            micro = f1_score(label_np, pred_np, average='micro')\n",
    "            macro = f1_score(label_np, pred_np, average='macro')\n",
    "            num_node_types += 1\n",
    "        # Averaging f1 score might not make sense, but in our example we only\n",
    "        # have one node type\n",
    "        micro /= num_node_types\n",
    "        macro /= num_node_types\n",
    "        accs.append((micro, macro))\n",
    "    if accs[1][0] > best_val:\n",
    "        best_val = accs[1][0]\n",
    "        best_model = copy.deepcopy(model)\n",
    "    return accs, best_model, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please do not change the following parameters\n",
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'hidden_size': 64,\n",
    "    'epochs': 100,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.003,\n",
    "    'attn_size': 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "PSO tensor([[   0,    0,    0,  ..., 3024, 3024, 3024],\n",
      "        [   8,   20,   51,  ..., 2948, 2983, 2991]])\n",
      "EDGE INDEX tensor([[   0,    0,    0,  ..., 3024, 3024, 3024],\n",
      "        [   8,   20,   51,  ..., 2948, 2983, 2991]])\n",
      "NODE FEATURE {'paper': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]])} LEN 3025\n",
      "ACM heterogeneous graph: {'paper': 3025} nodes, {('paper', 'author', 'paper'): 26256, ('paper', 'subject', 'paper'): 2207736} edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 3024, 3024, 3024]),\n",
      "             col=tensor([   8,   20,   51,  ..., 2948, 2983, 2991]),\n",
      "             size=(3025, 3025), nnz=26256, density=0.29%)\n",
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 3024, 3024, 3024]),\n",
      "             col=tensor([  75,  434,  534,  ..., 3020, 3021, 3022]),\n",
      "             size=(3025, 3025), nnz=2207736, density=24.13%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Device: {}\".format(args['device']))\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(\"acm.pkl\")\n",
    "\n",
    "print(\"PSO\", data[\"pap\"])\n",
    "\n",
    "# Message types\n",
    "message_type_1 = (\"paper\", \"author\", \"paper\")\n",
    "message_type_2 = (\"paper\", \"subject\", \"paper\")\n",
    "\n",
    "# Dictionary of edge indices\n",
    "edge_index = {}\n",
    "edge_index[message_type_1] = data['pap']\n",
    "edge_index[message_type_2] = data['psp']\n",
    "\n",
    "print(\"EDGE INDEX\", edge_index[message_type_1])\n",
    "\n",
    "# Dictionary of node features\n",
    "node_feature = {}\n",
    "node_feature[\"paper\"] = data['feature']\n",
    "\n",
    "print(\"NODE FEATURE\", node_feature, \"LEN\", len(node_feature['paper']))\n",
    "\n",
    "# Dictionary of node labels\n",
    "node_label = {}\n",
    "node_label[\"paper\"] = data['label']\n",
    "\n",
    "# Load the train, validation and test indices\n",
    "train_idx = {\"paper\": data['train_idx'].to(args['device'])}\n",
    "val_idx = {\"paper\": data['val_idx'].to(args['device'])}\n",
    "test_idx = {\"paper\": data['test_idx'].to(args['device'])}\n",
    "\n",
    "# Construct a deepsnap tensor backend HeteroGraph\n",
    "hetero_graph = HeteroGraph(\n",
    "    node_feature=node_feature,\n",
    "    node_label=node_label,\n",
    "    edge_index=edge_index,\n",
    "    directed=True\n",
    ")\n",
    "\n",
    "print(f\"ACM heterogeneous graph: {hetero_graph.num_nodes()} nodes, {hetero_graph.num_edges()} edges\")\n",
    "\n",
    "# Node feature and node label to device\n",
    "for key in hetero_graph.node_feature:\n",
    "    hetero_graph.node_feature[key] = hetero_graph.node_feature[key].to(args['device'])\n",
    "for key in hetero_graph.node_label:\n",
    "    hetero_graph.node_label[key] = hetero_graph.node_label[key].to(args['device'])\n",
    "\n",
    "# Edge_index to sparse tensor and to device\n",
    "for key in hetero_graph.edge_index:\n",
    "    edge_index = hetero_graph.edge_index[key]\n",
    "    adj = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(hetero_graph.num_nodes('paper'), hetero_graph.num_nodes('paper')))\n",
    "    hetero_graph.edge_index[key] = adj.t().to(args['device'])\n",
    "print(hetero_graph.edge_index[message_type_1])\n",
    "print(hetero_graph.edge_index[message_type_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HeteroGraph' object has no attribute 'node_to_graph_mapping'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hetero_graph\u001b[39m.\u001b[39;49mnode_to_graph_mapping[\u001b[39m'\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HeteroGraph' object has no attribute 'node_to_graph_mapping'"
     ]
    }
   ],
   "source": [
    "hetero_graph.node_to_graph_mapping['event'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.0000e+00, 1.3873e+09])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_graph.node_feature['event'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8729"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_graph.num_nodes('concept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E TO C 8955\n",
      "TYPE ('event', 'related', 'concept')\n",
      "\t Feature 2\n",
      "\t Feature 5\n",
      "TYPE ('event', 'similar', 'event')\n",
      "\t Feature 2\n",
      "\t Feature 2\n",
      "TYPE ('concept', 'related', 'event')\n",
      "\t Feature 5\n",
      "\t Feature 2\n",
      "here\n",
      "KEY ('event', 'related', 'concept')\n",
      "KEY NUMS ('event', 'related', 'concept') 8487 8729\n",
      "MAX EDGES tensor(8728) tensor(8728)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     edge_index \u001b[39m=\u001b[39m hetero_graph\u001b[39m.\u001b[39medge_index[key]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMAX EDGES\u001b[39m\u001b[39m\"\u001b[39m, edge_index[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmax(), edge_index[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mmax())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     adj \u001b[39m=\u001b[39m SparseTensor(row\u001b[39m=\u001b[39;49medge_index[\u001b[39m0\u001b[39;49m], col\u001b[39m=\u001b[39;49medge_index[\u001b[39m1\u001b[39;49m], sparse_sizes\u001b[39m=\u001b[39;49m(hetero_graph\u001b[39m.\u001b[39;49mnum_nodes(key[\u001b[39m0\u001b[39;49m]), hetero_graph\u001b[39m.\u001b[39;49mnum_nodes(key[\u001b[39m2\u001b[39;49m])))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m#hetero_graph.edge_index[key] = adj.t().to(args['device'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Code/MLG-Predicting-Impacful-Events/Heterogeneus/Project.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhere 2\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch_sparse/tensor.py:26\u001b[0m, in \u001b[0;36mSparseTensor.__init__\u001b[0;34m(self, row, rowptr, col, value, sparse_sizes, is_sorted, trust_data)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     18\u001b[0m     row: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     trust_data: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m ):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage \u001b[39m=\u001b[39m SparseStorage(\n\u001b[1;32m     27\u001b[0m         row\u001b[39m=\u001b[39;49mrow,\n\u001b[1;32m     28\u001b[0m         rowptr\u001b[39m=\u001b[39;49mrowptr,\n\u001b[1;32m     29\u001b[0m         col\u001b[39m=\u001b[39;49mcol,\n\u001b[1;32m     30\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m     31\u001b[0m         sparse_sizes\u001b[39m=\u001b[39;49msparse_sizes,\n\u001b[1;32m     32\u001b[0m         rowcount\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     33\u001b[0m         colptr\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     34\u001b[0m         colcount\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     35\u001b[0m         csr2csc\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     36\u001b[0m         csc2csr\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     37\u001b[0m         is_sorted\u001b[39m=\u001b[39;49mis_sorted,\n\u001b[1;32m     38\u001b[0m         trust_data\u001b[39m=\u001b[39;49mtrust_data,\n\u001b[1;32m     39\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch_sparse/storage.py:69\u001b[0m, in \u001b[0;36mSparseStorage.__init__\u001b[0;34m(self, row, rowptr, col, value, sparse_sizes, rowcount, colptr, colcount, csr2csc, csc2csr, is_sorted, trust_data)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[39massert\u001b[39;00m rowptr\u001b[39m.\u001b[39mnumel() \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m M\n\u001b[1;32m     68\u001b[0m     \u001b[39melif\u001b[39;00m row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m row\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m         \u001b[39massert\u001b[39;00m trust_data \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(row\u001b[39m.\u001b[39mmax()) \u001b[39m<\u001b[39m M\n\u001b[1;32m     71\u001b[0m N: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m sparse_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m sparse_sizes[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"./1_concepts_similar.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "hetero_graph = HeteroGraph(G, netlib=nx)\n",
    "\n",
    "\n",
    "count_event_to_concept = 0\n",
    "for edge in G.edges(data=True):\n",
    "    if G.nodes[edge[0]]['node_type'] == 'concept' and G.nodes[edge[1]]['node_type'] == 'event':\n",
    "        count_event_to_concept += 1\n",
    "\n",
    "print(\"E TO C\", count_event_to_concept)\n",
    "\n",
    "# # Construct a deepsnap tensor backend HeteroGraph\n",
    "# # hetero_graph = HeteroGraph(\n",
    "# #     node_feature=node_feature,\n",
    "# #     node_label=node_label,\n",
    "# #     edge_index=edge_index,\n",
    "# #     directed=True\n",
    "# # )\n",
    "\n",
    "# hetero_graph = HeteroGraph(G)\n",
    "\n",
    "for message_type in hetero_graph.message_types:\n",
    "    print(\"TYPE\", message_type)\n",
    "    print(\"\\t Feature\", hetero_graph.num_node_features(message_type[0]))\n",
    "    print(\"\\t Feature\", hetero_graph.num_node_features(message_type[2]))\n",
    "\n",
    "\n",
    "# Node feature and node label to device\n",
    "\n",
    "for key in hetero_graph.node_feature:\n",
    "    hetero_graph.node_feature[key] = hetero_graph.node_feature[key].to(args['device'])\n",
    "# for key in hetero_graph.node_label:\n",
    "#     hetero_graph.node_label[key] = hetero_graph.node_label[key].to(args['device'])\n",
    "\n",
    "print(\"here\")\n",
    "\n",
    "\n",
    "# Edge_index to sparse tensor and to device\n",
    "for key in hetero_graph.edge_index:\n",
    "    print(\"KEY\", key)\n",
    "    print(\"KEY NUMS\", key, hetero_graph.num_nodes(key[0]), hetero_graph.num_nodes(key[2]))\n",
    "    edge_index = hetero_graph.edge_index[key]\n",
    "    print(\"MAX EDGES\", edge_index[0].max(), edge_index[1].max())\n",
    "    adj = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(hetero_graph.num_nodes(key[0]), hetero_graph.num_nodes(key[2])))\n",
    "    #hetero_graph.edge_index[key] = adj.t().to(args['device'])\n",
    "\n",
    "print(\"here 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 17910]) tensor(8448) tensor(8448)\n",
      "torch.Size([2, 17490]) tensor(8728) tensor(8728)\n"
     ]
    }
   ],
   "source": [
    "edge_index1 = hetero_graph.edge_index[('concept', 'related', 'event')]\n",
    "edge_index2 = hetero_graph.edge_index[('event', 'related', 'concept')]\n",
    "print(edge_index1.shape, edge_index1[0].max(), edge_index1[1].max())\n",
    "print(edge_index2.shape, edge_index2[0].max(), edge_index2[1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8448)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8448)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss 1.09952, train micro 33.33%, train macro 16.67%, valid micro 33.33%, valid macro 16.67%, test micro 35.81%, test macro 17.58%\n",
      "Epoch 2: loss 1.08864, train micro 51.17%, train macro 42.48%, valid micro 36.33%, valid macro 22.55%, test micro 40.09%, test macro 26.18%\n",
      "Epoch 3: loss 1.05408, train micro 66.33%, train macro 55.04%, valid micro 65.67%, valid macro 54.83%, test micro 62.64%, test macro 52.28%\n",
      "Epoch 4: loss 0.98376, train micro 66.33%, train macro 54.35%, valid micro 66.33%, valid macro 54.98%, test micro 65.18%, test macro 53.86%\n",
      "Epoch 5: loss 0.86934, train micro 66.67%, train macro 55.02%, valid micro 66.0%, valid macro 54.13%, test micro 64.94%, test macro 53.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(args[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(model, optimizer, hetero_graph, train_idx)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     accs, best_model, best_val \u001b[39m=\u001b[39m test(model, hetero_graph, [train_idx, val_idx, test_idx], best_model, best_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: loss \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(loss,\u001b[39m \u001b[39m\u001b[39m5\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain micro \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(accs[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%, train macro \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(accs[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid micro \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(accs[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%, valid macro \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(accs[\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest micro \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(accs[\u001b[39m2\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%, test macro \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(accs[\u001b[39m2\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m best_accs, _, _ \u001b[39m=\u001b[39m test(best_model, hetero_graph, [train_idx, val_idx, test_idx])\n",
      "\u001b[1;32m/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m accs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m indices:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     preds \u001b[39m=\u001b[39m model(graph\u001b[39m.\u001b[39;49mnode_feature, graph\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     num_node_types \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     micro \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m x \u001b[39m=\u001b[39m forward_op(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbns1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m x \u001b[39m=\u001b[39m forward_op(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelus1)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs2(x, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m x \u001b[39m=\u001b[39m forward_op(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbns2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m x \u001b[39m=\u001b[39m forward_op(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelus2)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     node_feature_dst \u001b[39m=\u001b[39m node_features[dst_type]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     edge_index \u001b[39m=\u001b[39m edge_indices[message_key]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     message_type_emb[message_key] \u001b[39m=\u001b[39m (\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs[message_key](\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m             node_feature_src,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m             node_feature_dst,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m             edge_index,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m node_emb \u001b[39m=\u001b[39m {dst: [] \u001b[39mfor\u001b[39;00m _, _, dst \u001b[39min\u001b[39;00m message_type_emb\u001b[39m.\u001b[39mkeys()}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m mapping \u001b[39m=\u001b[39m {}        \n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     node_feature_src,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m############# Your code here #############\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m## (~1 line of code)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, node_feature_src\u001b[39m=\u001b[39;49mnode_feature_src, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                 node_feature_dst\u001b[39m=\u001b[39;49mnode_feature_dst, size\u001b[39m=\u001b[39;49msize, res_n_id\u001b[39m=\u001b[39;49mres_n_id)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:431\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m         edge_index, msg_aggr_kwargs \u001b[39m=\u001b[39m res\n\u001b[0;32m--> 431\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage_and_aggregate(edge_index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_aggr_kwargs)\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    433\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "\u001b[1;32m/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage_and_aggregate\u001b[39m(\u001b[39mself\u001b[39m, edge_index, node_feature_src):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m############# Your code here #############\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m## https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m## 3. Here edge_index is torch_sparse SparseTensor.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     out \u001b[39m=\u001b[39m matmul(edge_index, node_feature_src, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m##########################################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/galgantar/Documents/Faks/MLG/Project/Project.ipynb#X12sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch_sparse/matmul.py:160\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(src, other, reduce)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Matrix product of a sparse tensor with either another sparse tensor or a\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m dense tensor. The sparse tensor represents an adjacency matrix and is\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m stored as a list of edges. This method multiplies elements along the rows\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39m:rtype: (:class:`Tensor`)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m spmm(src, other, reduce)\n\u001b[1;32m    161\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, SparseTensor):\n\u001b[1;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m spspmm(src, other, reduce)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch_sparse/matmul.py:85\u001b[0m, in \u001b[0;36mspmm\u001b[0;34m(src, other, reduce)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m spmm_sum(src, other)\n\u001b[1;32m     84\u001b[0m \u001b[39melif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m spmm_mean(src, other)\n\u001b[1;32m     86\u001b[0m \u001b[39melif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m spmm_min(src, other)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch_sparse/matmul.py:55\u001b[0m, in \u001b[0;36mspmm_mean\u001b[0;34m(src, other)\u001b[0m\n\u001b[1;32m     52\u001b[0m     csr2csc \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mcsr2csc()\n\u001b[1;32m     53\u001b[0m     colptr \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mcolptr()\n\u001b[0;32m---> 55\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorch_sparse\u001b[39m.\u001b[39;49mspmm_mean(row, rowptr, col, value, rowcount,\n\u001b[1;32m     56\u001b[0m                                         colptr, csr2csc, other)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_val = 0\n",
    "\n",
    "model = HeteroGNN(hetero_graph, args, aggr=\"mean\").to(args['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "for epoch in range(args['epochs']):\n",
    "    loss = train(model, optimizer, hetero_graph, train_idx)\n",
    "    accs, best_model, best_val = test(model, hetero_graph, [train_idx, val_idx, test_idx], best_model, best_val)\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}: loss {round(loss, 5)}, \"\n",
    "        f\"train micro {round(accs[0][0] * 100, 2)}%, train macro {round(accs[0][1] * 100, 2)}%, \"\n",
    "        f\"valid micro {round(accs[1][0] * 100, 2)}%, valid macro {round(accs[1][1] * 100, 2)}%, \"\n",
    "        f\"test micro {round(accs[2][0] * 100, 2)}%, test macro {round(accs[2][1] * 100, 2)}%\"\n",
    "    )\n",
    "best_accs, _, _ = test(best_model, hetero_graph, [train_idx, val_idx, test_idx])\n",
    "print(\n",
    "    f\"Best model: \"\n",
    "    f\"train micro {round(best_accs[0][0] * 100, 2)}%, train macro {round(best_accs[0][1] * 100, 2)}%, \"\n",
    "    f\"valid micro {round(best_accs[1][0] * 100, 2)}%, valid macro {round(best_accs[1][1] * 100, 2)}%, \"\n",
    "    f\"test micro {round(best_accs[2][0] * 100, 2)}%, test macro {round(best_accs[2][1] * 100, 2)}%\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
