{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/text/dataset_embedded.pkl')\n",
    "df = df.sample(frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(tdata.Dataset):\n",
    "  def __init__(self, df, list_IDs):\n",
    "    self.df = df.loc[list_IDs]\n",
    "    self.list_IDs = list(self.df.index)\n",
    "    self.langs = list(df['lang'].unique())\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.list_IDs)\n",
    "  \n",
    "  def lang_to_onehot(self, lang):\n",
    "    lang = self.langs.index(lang)\n",
    "    onehot = torch.zeros(len(self.langs))\n",
    "    onehot[lang] = 1\n",
    "    return onehot\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    idx = self.list_IDs[index]\n",
    "    row = self.df.loc[idx]\n",
    "    \n",
    "    article_count = torch.tensor([row['article_count']])\n",
    "    lang = self.lang_to_onehot(row['lang'])\n",
    "    date = torch.tensor([row['event_date']])\n",
    "\n",
    "    title_embed = torch.tensor(row['title_embed'][0])\n",
    "    #summary_embed = torch.tensor(row['summary_embed'][0])\n",
    "\n",
    "    X = torch.cat((lang, date, title_embed,))\n",
    "\n",
    "    return X, article_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "params = {\n",
    "  'batch_size': 64,\n",
    "  'shuffle': True,\n",
    "  'num_workers': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(df.index, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset(df, train_ids)\n",
    "test_dataset = Dataset(df, train_ids) # same as train\n",
    "# test_dataset = Dataset(df, test_ids)\n",
    "\n",
    "train_generator = tdata.DataLoader(train_dataset, **params)\n",
    "test_generator = tdata.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self, input_size):\n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    self.linear1 = nn.Linear(input_size, 128)\n",
    "    self.linear2 = nn.Linear(128, 64)\n",
    "    self.linear3 = nn.Linear(64, 32)\n",
    "    self.linear4 = nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \n",
    "    x = F.relu(self.linear1(x))\n",
    "    x = F.relu(self.linear2(x))\n",
    "    x = F.relu(self.linear3(x))\n",
    "    x = F.relu(self.linear4(x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(1*768 + 4 + 1)\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 585.3194452921549\n",
      "Epoch: 1, Loss: 721.2002360026041\n",
      "Epoch: 2, Loss: 685.7989908854166\n",
      "Epoch: 3, Loss: 609.0653940836588\n",
      "Epoch: 4, Loss: 720.4079793294271\n",
      "Epoch: 5, Loss: 724.5191040039062\n",
      "Epoch: 6, Loss: 824.8701578776041\n",
      "Epoch: 7, Loss: 957.0680745442709\n",
      "Epoch: 8, Loss: 1050.7671712239583\n",
      "Epoch: 9, Loss: 813.27197265625\n",
      "Epoch: 10, Loss: 591.6645456949869\n",
      "Epoch: 11, Loss: 589.4091440836588\n",
      "Epoch: 12, Loss: 609.3223368326823\n",
      "Epoch: 13, Loss: 597.2530873616537\n",
      "Epoch: 14, Loss: 699.2029418945312\n",
      "Epoch: 15, Loss: 699.3956502278646\n",
      "Epoch: 16, Loss: 593.1491139729818\n",
      "Epoch: 17, Loss: 593.0848744710287\n",
      "Epoch: 18, Loss: 748.7218424479166\n",
      "Epoch: 19, Loss: 609.4793599446615\n",
      "Epoch: 20, Loss: 622.6905822753906\n",
      "Epoch: 21, Loss: 628.2363077799479\n",
      "Epoch: 22, Loss: 1056.8125\n",
      "Epoch: 23, Loss: 725.0044352213541\n",
      "Epoch: 24, Loss: 589.2949447631836\n",
      "Epoch: 25, Loss: 695.1917521158854\n",
      "Epoch: 26, Loss: 587.938850402832\n",
      "Epoch: 27, Loss: 998.4147135416666\n",
      "Epoch: 28, Loss: 953.2353515625\n",
      "Epoch: 29, Loss: 976.8671061197916\n",
      "Epoch: 30, Loss: 583.0854543050131\n",
      "Epoch: 31, Loss: 579.630978902181\n",
      "Epoch: 32, Loss: 722.3279418945312\n",
      "Epoch: 33, Loss: 980.378662109375\n",
      "Epoch: 34, Loss: 585.5835266113281\n",
      "Epoch: 35, Loss: 585.8761571248373\n",
      "Epoch: 36, Loss: 594.0698293050131\n",
      "Epoch: 37, Loss: 1004.6813151041666\n",
      "Epoch: 38, Loss: 609.9789733886719\n",
      "Epoch: 39, Loss: 680.5530395507812\n",
      "Epoch: 40, Loss: 976.1890462239584\n",
      "Epoch: 41, Loss: 680.2532755533854\n",
      "Epoch: 42, Loss: 624.0181376139323\n",
      "Epoch: 43, Loss: 691.9299723307291\n",
      "Epoch: 44, Loss: 630.0134989420573\n",
      "Epoch: 45, Loss: 596.7249247233073\n",
      "Epoch: 46, Loss: 717.0320231119791\n",
      "Epoch: 47, Loss: 620.5065612792969\n",
      "Epoch: 48, Loss: 960.50830078125\n",
      "Epoch: 49, Loss: 605.8607228597006\n",
      "Epoch: 50, Loss: 619.3717244466146\n",
      "Epoch: 51, Loss: 682.6799723307291\n",
      "Epoch: 52, Loss: 957.2108561197916\n",
      "Epoch: 53, Loss: 593.8128865559896\n",
      "Epoch: 54, Loss: 616.1313680013021\n",
      "Epoch: 55, Loss: 607.8449096679688\n",
      "Epoch: 56, Loss: 1091.1573893229167\n",
      "Epoch: 57, Loss: 585.0054016113281\n",
      "Epoch: 58, Loss: 696.1410115559896\n",
      "Epoch: 59, Loss: 624.710459391276\n",
      "Epoch: 60, Loss: 588.5954869588217\n",
      "Epoch: 61, Loss: 967.081787109375\n",
      "Epoch: 62, Loss: 738.4583333333334\n",
      "Epoch: 63, Loss: 978.5729166666666\n",
      "Epoch: 64, Loss: 714.5696411132812\n",
      "Epoch: 65, Loss: 615.9600728352865\n",
      "Epoch: 66, Loss: 969.3514811197916\n",
      "Epoch: 67, Loss: 741.4346110026041\n",
      "Epoch: 68, Loss: 953.6992594401041\n",
      "Epoch: 69, Loss: 592.2997690836588\n",
      "Epoch: 70, Loss: 591.421875\n",
      "Epoch: 71, Loss: 977.5380045572916\n",
      "Epoch: 72, Loss: 601.1072540283203\n",
      "Epoch: 73, Loss: 723.9980672200521\n",
      "Epoch: 74, Loss: 605.6180572509766\n",
      "Epoch: 75, Loss: 600.579091389974\n",
      "Epoch: 76, Loss: 591.7716064453125\n",
      "Epoch: 77, Loss: 582.521603902181\n",
      "Epoch: 78, Loss: 625.0673217773438\n",
      "Epoch: 79, Loss: 1085.7401529947917\n",
      "Epoch: 80, Loss: 589.5233408610026\n",
      "Epoch: 81, Loss: 596.139658610026\n",
      "Epoch: 82, Loss: 592.5424397786459\n",
      "Epoch: 83, Loss: 949.5738932291666\n",
      "Epoch: 84, Loss: 812.4226481119791\n",
      "Epoch: 85, Loss: 608.0590260823568\n",
      "Epoch: 86, Loss: 810.8595784505209\n",
      "Epoch: 87, Loss: 613.0623067220052\n",
      "Epoch: 88, Loss: 952.3146158854166\n",
      "Epoch: 89, Loss: 617.1377360026041\n",
      "Epoch: 90, Loss: 1048.261962890625\n",
      "Epoch: 91, Loss: 585.5478388468424\n",
      "Epoch: 92, Loss: 1004.360107421875\n",
      "Epoch: 93, Loss: 613.0337575276693\n",
      "Epoch: 94, Loss: 682.5871988932291\n",
      "Epoch: 95, Loss: 621.512929280599\n",
      "Epoch: 96, Loss: 605.2754618326823\n",
      "Epoch: 97, Loss: 953.3424072265625\n",
      "Epoch: 98, Loss: 580.9513880411783\n",
      "Epoch: 99, Loss: 695.5343424479166\n",
      "Epoch: 100, Loss: 622.8119201660156\n",
      "Epoch: 101, Loss: 1180.895263671875\n",
      "Epoch: 102, Loss: 725.8894653320312\n",
      "Epoch: 103, Loss: 594.5052083333334\n",
      "Epoch: 104, Loss: 950.3090413411459\n",
      "Epoch: 105, Loss: 586.7611872355143\n",
      "Epoch: 106, Loss: 598.3094126383463\n",
      "Epoch: 107, Loss: 591.5360717773438\n",
      "Epoch: 108, Loss: 592.4924774169922\n",
      "Epoch: 109, Loss: 961.1078287760416\n",
      "Epoch: 110, Loss: 581.215471903483\n",
      "Epoch: 111, Loss: 700.2021687825521\n",
      "Epoch: 112, Loss: 983.9545084635416\n",
      "Epoch: 113, Loss: 971.2642415364584\n",
      "Epoch: 114, Loss: 614.8180948893229\n",
      "Epoch: 115, Loss: 580.5802459716797\n",
      "Epoch: 116, Loss: 605.2683258056641\n",
      "Epoch: 117, Loss: 724.7974446614584\n",
      "Epoch: 118, Loss: 599.7868448893229\n",
      "Epoch: 119, Loss: 681.27392578125\n",
      "Epoch: 120, Loss: 593.1348368326823\n",
      "Epoch: 121, Loss: 603.3626556396484\n",
      "Epoch: 122, Loss: 676.6560668945312\n",
      "Epoch: 123, Loss: 695.605712890625\n",
      "Epoch: 124, Loss: 592.7565561930338\n",
      "Epoch: 125, Loss: 678.4618123372396\n",
      "Epoch: 126, Loss: 599.8582153320312\n",
      "Epoch: 127, Loss: 589.7303237915039\n",
      "Epoch: 128, Loss: 584.0775451660156\n",
      "Epoch: 129, Loss: 633.9533182779948\n",
      "Epoch: 130, Loss: 593.1419728597006\n",
      "Epoch: 131, Loss: 698.7961018880209\n",
      "Epoch: 132, Loss: 602.5133107503256\n",
      "Epoch: 133, Loss: 608.9083709716797\n",
      "Epoch: 134, Loss: 677.2698771158854\n",
      "Epoch: 135, Loss: 681.5451456705729\n",
      "Epoch: 136, Loss: 973.4483235677084\n",
      "Epoch: 137, Loss: 671.8811645507812\n",
      "Epoch: 138, Loss: 589.2378463745117\n",
      "Epoch: 139, Loss: 983.9759114583334\n",
      "Epoch: 140, Loss: 720.6078287760416\n",
      "Epoch: 141, Loss: 821.1658935546875\n",
      "Epoch: 142, Loss: 622.4479166666666\n",
      "Epoch: 143, Loss: 956.8611246744791\n",
      "Epoch: 144, Loss: 593.4774322509766\n",
      "Epoch: 145, Loss: 590.9508107503256\n",
      "Epoch: 146, Loss: 693.385986328125\n",
      "Epoch: 147, Loss: 690.2955322265625\n",
      "Epoch: 148, Loss: 588.7239583333334\n",
      "Epoch: 149, Loss: 597.5028940836588\n",
      "Epoch: 150, Loss: 680.9170532226562\n",
      "Epoch: 151, Loss: 581.4081802368164\n",
      "Epoch: 152, Loss: 592.364003499349\n",
      "Epoch: 153, Loss: 583.9276631673177\n",
      "Epoch: 154, Loss: 583.0711797078451\n",
      "Epoch: 155, Loss: 597.5028940836588\n",
      "Epoch: 156, Loss: 587.1394678751627\n",
      "Epoch: 157, Loss: 583.6207555135092\n",
      "Epoch: 158, Loss: 813.0650227864584\n",
      "Epoch: 159, Loss: 593.7415110270182\n",
      "Epoch: 160, Loss: 1048.897216796875\n",
      "Epoch: 161, Loss: 1098.3661295572917\n",
      "Epoch: 162, Loss: 688.1971435546875\n",
      "Epoch: 163, Loss: 612.5484161376953\n",
      "Epoch: 164, Loss: 623.2758483886719\n",
      "Epoch: 165, Loss: 1049.0185546875\n",
      "Epoch: 166, Loss: 610.2216440836588\n",
      "Epoch: 167, Loss: 627.3227233886719\n",
      "Epoch: 168, Loss: 592.3354543050131\n",
      "Epoch: 169, Loss: 611.9988403320312\n",
      "Epoch: 170, Loss: 609.9361521402994\n",
      "Epoch: 171, Loss: 758.6070556640625\n",
      "Epoch: 172, Loss: 717.1961873372396\n",
      "Epoch: 173, Loss: 690.1170857747396\n",
      "Epoch: 174, Loss: 599.8296661376953\n",
      "Epoch: 175, Loss: 592.8564809163412\n",
      "Epoch: 176, Loss: 594.4338328043619\n",
      "Epoch: 177, Loss: 619.992665608724\n",
      "Epoch: 178, Loss: 952.0791015625\n",
      "Epoch: 179, Loss: 721.5428263346354\n",
      "Epoch: 180, Loss: 613.3406626383463\n",
      "Epoch: 181, Loss: 604.9257354736328\n",
      "Epoch: 182, Loss: 968.3236490885416\n",
      "Epoch: 183, Loss: 589.6232630411783\n",
      "Epoch: 184, Loss: 583.4280471801758\n",
      "Epoch: 185, Loss: 596.4465688069662\n",
      "Epoch: 186, Loss: 606.9955647786459\n",
      "Epoch: 187, Loss: 589.2949447631836\n",
      "Epoch: 188, Loss: 589.0380020141602\n",
      "Epoch: 189, Loss: 963.577392578125\n",
      "Epoch: 190, Loss: 964.2625325520834\n",
      "Epoch: 191, Loss: 1051.2239583333333\n",
      "Epoch: 192, Loss: 614.9822540283203\n",
      "Epoch: 193, Loss: 709.9446411132812\n",
      "Epoch: 194, Loss: 733.8690185546875\n",
      "Epoch: 195, Loss: 950.1520182291666\n",
      "Epoch: 196, Loss: 604.8543599446615\n",
      "Epoch: 197, Loss: 985.7102864583334\n",
      "Epoch: 198, Loss: 721.5642293294271\n",
      "Epoch: 199, Loss: 584.6342595418295\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  for x, y in train_generator:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(x.float())\n",
    "    loss = criteria(outputs, y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    test_loss = []\n",
    "    \n",
    "    for x, y in test_generator:\n",
    "      x, y = x.to(device), y.to(device)\n",
    "\n",
    "      outputs = model(x.float())\n",
    "      loss = criteria(outputs, y.float())\n",
    "      test_loss.append(loss.item())\n",
    "\n",
    "  print('Epoch: {}, Loss: {}'.format(epoch, np.mean(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and save them in a pandas dataframe along with their true values\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  true = []\n",
    "  prd = []\n",
    "  for x, y in test_generator:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    outputs = model(x.float())\n",
    "    true.append(y.cpu().numpy())\n",
    "    prd.append(outputs.cpu().numpy())\n",
    "\n",
    "true = np.concatenate(true)\n",
    "prd = np.concatenate(prd)\n",
    "outputs = pd.DataFrame({'true': true.flatten(), 'pred': prd.flatten()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [true, pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[outputs['pred'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
