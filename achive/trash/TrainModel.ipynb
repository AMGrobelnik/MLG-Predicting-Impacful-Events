{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, n_langs=4, llm_embed_size=768):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_dim = n_langs + 2*llm_embed_size + 1 # timestamp\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(in_features=self.input_dim, out_features=1024) # First hidden layer\n",
    "        self.fc2 = nn.Linear(1024, 512) # Second hidden layer\n",
    "        self.fc3 = nn.Linear(512, 128) # Second hidden layer\n",
    "        self.fc4 = nn.Linear(128, 64) # Second hidden layer\n",
    "        self.fc5 = nn.Linear(64, 1) # Output layer\n",
    "\n",
    "        self.fakju6 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Add hidden layers with relu activation function\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = F.relu(self.fc3(x))\n",
    "        # x = F.relu(self.fc4(x))\n",
    "        # x = F.relu(self.fc5(x))\n",
    "\n",
    "        x = self.fakju6(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_count</th>\n",
       "      <th>event_date</th>\n",
       "      <th>title_embed</th>\n",
       "      <th>summary_embed</th>\n",
       "      <th>lang_deu</th>\n",
       "      <th>lang_eng</th>\n",
       "      <th>lang_spa</th>\n",
       "      <th>lang_zho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e_11</th>\n",
       "      <td>7</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>[[0.47470707, -0.08501352, 0.26899937, -0.3635...</td>\n",
       "      <td>[[0.3377615, -0.26158097, 0.3140225, -0.212071...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_10</th>\n",
       "      <td>221</td>\n",
       "      <td>1.387411e+09</td>\n",
       "      <td>[[0.17094071, -0.18888026, 0.28712985, -0.3610...</td>\n",
       "      <td>[[0.1786896, -0.11662727, 0.19326286, -0.20948...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_13</th>\n",
       "      <td>9</td>\n",
       "      <td>1.387498e+09</td>\n",
       "      <td>[[0.2537402, -0.032281302, 0.37904784, -0.3181...</td>\n",
       "      <td>[[0.026874868, -0.09318099, 0.03552014, -0.026...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.387066e+09</td>\n",
       "      <td>[[0.23880291, 0.03649398, 0.32137018, -0.17099...</td>\n",
       "      <td>[[0.46094257, -0.36103615, 0.31917268, -0.6018...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_15</th>\n",
       "      <td>8</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>[[0.3985864, -0.06734807, 0.40732777, -0.46121...</td>\n",
       "      <td>[[0.5053371, -0.062929116, 0.27972195, -0.4317...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_count    event_date  \\\n",
       "id                                 \n",
       "e_11             7  1.387325e+09   \n",
       "e_10           221  1.387411e+09   \n",
       "e_13             9  1.387498e+09   \n",
       "e_12             1  1.387066e+09   \n",
       "e_15             8  1.387325e+09   \n",
       "\n",
       "                                            title_embed  \\\n",
       "id                                                        \n",
       "e_11  [[0.47470707, -0.08501352, 0.26899937, -0.3635...   \n",
       "e_10  [[0.17094071, -0.18888026, 0.28712985, -0.3610...   \n",
       "e_13  [[0.2537402, -0.032281302, 0.37904784, -0.3181...   \n",
       "e_12  [[0.23880291, 0.03649398, 0.32137018, -0.17099...   \n",
       "e_15  [[0.3985864, -0.06734807, 0.40732777, -0.46121...   \n",
       "\n",
       "                                          summary_embed  lang_deu  lang_eng  \\\n",
       "id                                                                            \n",
       "e_11  [[0.3377615, -0.26158097, 0.3140225, -0.212071...     False      True   \n",
       "e_10  [[0.1786896, -0.11662727, 0.19326286, -0.20948...     False      True   \n",
       "e_13  [[0.026874868, -0.09318099, 0.03552014, -0.026...     False      True   \n",
       "e_12  [[0.46094257, -0.36103615, 0.31917268, -0.6018...     False      True   \n",
       "e_15  [[0.5053371, -0.062929116, 0.27972195, -0.4317...     False      True   \n",
       "\n",
       "      lang_spa  lang_zho  \n",
       "id                        \n",
       "e_11     False     False  \n",
       "e_10     False     False  \n",
       "e_13     False     False  \n",
       "e_12     False     False  \n",
       "e_15     False     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('../data/text/dataset_embedded.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly drop 75% of the data\n",
    "df = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_cols = ['lang_eng', 'lang_deu', 'lang_spa', 'lang_zho']\n",
    "x_cols = ['event_date', 'title_embed', 'summary_embed']\n",
    "y_cols = ['article_count']\n",
    "def get_xy(df):\n",
    "    date = df['event_date'].values\n",
    "    langs = df[lang_cols].values\n",
    "    langs = torch.tensor(langs, dtype=torch.bool)\n",
    "    date = torch.tensor(date, dtype=torch.float64)\n",
    "    date = date.unsqueeze(1)\n",
    "\n",
    "    #title_embeds = torch.tensor(df['title_embed'].values.tolist(), dtype=torch.float64).reshape(-1, 768)\n",
    "    #summary_embeds = torch.tensor(df['summary_embed'].values.tolist(), dtype=torch.float64).reshape(-1, 768)\n",
    "\n",
    "    #X = torch.cat((date, langs, title_embeds, summary_embeds), dim=1)\n",
    "    X = torch.cat((date, langs), dim=1)\n",
    "    Y = df[y_cols].to_numpy(dtype=np.float32)\n",
    "    return X.float(), torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(llm_embed_size=0, n_langs=0)\n",
    "criterion = nn.MSELoss() # RMSLELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X, train_Y = get_xy(train_df)\n",
    "# test_X, test_Y = get_xy(test_df)\n",
    "\n",
    "test_X = torch.tensor([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    [3, 3, 3, 3, 3],\n",
    "    [4, 4, 4, 4, 4],\n",
    "    [5, 5, 5, 5, 5],\n",
    "    [6, 6, 6, 6, 6]\n",
    "], dtype=torch.float32)\n",
    "test_Y = torch.tensor([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [4],\n",
    "    [5],\n",
    "    [6]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# train_ds = TensorDataset(train_X, train_Y)\n",
    "test_ds = TensorDataset(test_X, test_Y)\n",
    "train_ds = test_ds\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 3.4276, test loss 3.4275\n",
      "Epoch 1: train loss 3.4275, test loss 3.4274\n",
      "Epoch 2: train loss 3.4274, test loss 3.4273\n",
      "Epoch 3: train loss 3.4273, test loss 3.4273\n",
      "Epoch 4: train loss 3.4273, test loss 3.4272\n",
      "Epoch 5: train loss 3.4272, test loss 3.4271\n",
      "Epoch 6: train loss 3.4271, test loss 3.4270\n",
      "Epoch 7: train loss 3.4270, test loss 3.4270\n",
      "Epoch 8: train loss 3.4270, test loss 3.4269\n",
      "Epoch 9: train loss 3.4269, test loss 3.4268\n",
      "Epoch 10: train loss 3.4268, test loss 3.4267\n",
      "Epoch 11: train loss 3.4267, test loss 3.4267\n",
      "Epoch 12: train loss 3.4267, test loss 3.4266\n",
      "Epoch 13: train loss 3.4266, test loss 3.4265\n",
      "Epoch 14: train loss 3.4265, test loss 3.4264\n",
      "Epoch 15: train loss 3.4264, test loss 3.4264\n",
      "Epoch 16: train loss 3.4264, test loss 3.4263\n",
      "Epoch 17: train loss 3.4263, test loss 3.4262\n",
      "Epoch 18: train loss 3.4262, test loss 3.4261\n",
      "Epoch 19: train loss 3.4261, test loss 3.4261\n",
      "Epoch 20: train loss 3.4261, test loss 3.4260\n",
      "Epoch 21: train loss 3.4260, test loss 3.4259\n",
      "Epoch 22: train loss 3.4259, test loss 3.4258\n",
      "Epoch 23: train loss 3.4258, test loss 3.4258\n",
      "Epoch 24: train loss 3.4258, test loss 3.4257\n",
      "Epoch 25: train loss 3.4257, test loss 3.4256\n",
      "Epoch 26: train loss 3.4256, test loss 3.4255\n",
      "Epoch 27: train loss 3.4255, test loss 3.4255\n",
      "Epoch 28: train loss 3.4255, test loss 3.4254\n",
      "Epoch 29: train loss 3.4254, test loss 3.4253\n",
      "Epoch 30: train loss 3.4253, test loss 3.4252\n",
      "Epoch 31: train loss 3.4252, test loss 3.4251\n",
      "Epoch 32: train loss 3.4251, test loss 3.4251\n",
      "Epoch 33: train loss 3.4251, test loss 3.4250\n",
      "Epoch 34: train loss 3.4250, test loss 3.4249\n",
      "Epoch 35: train loss 3.4249, test loss 3.4248\n",
      "Epoch 36: train loss 3.4248, test loss 3.4248\n",
      "Epoch 37: train loss 3.4248, test loss 3.4247\n",
      "Epoch 38: train loss 3.4247, test loss 3.4246\n",
      "Epoch 39: train loss 3.4246, test loss 3.4245\n",
      "Epoch 40: train loss 3.4245, test loss 3.4245\n",
      "Epoch 41: train loss 3.4245, test loss 3.4244\n",
      "Epoch 42: train loss 3.4244, test loss 3.4243\n",
      "Epoch 43: train loss 3.4243, test loss 3.4242\n",
      "Epoch 44: train loss 3.4242, test loss 3.4242\n",
      "Epoch 45: train loss 3.4242, test loss 3.4241\n",
      "Epoch 46: train loss 3.4241, test loss 3.4240\n",
      "Epoch 47: train loss 3.4240, test loss 3.4239\n",
      "Epoch 48: train loss 3.4239, test loss 3.4239\n",
      "Epoch 49: train loss 3.4239, test loss 3.4238\n",
      "Epoch 50: train loss 3.4238, test loss 3.4237\n",
      "Epoch 51: train loss 3.4237, test loss 3.4236\n",
      "Epoch 52: train loss 3.4236, test loss 3.4236\n",
      "Epoch 53: train loss 3.4236, test loss 3.4235\n",
      "Epoch 54: train loss 3.4235, test loss 3.4234\n",
      "Epoch 55: train loss 3.4234, test loss 3.4233\n",
      "Epoch 56: train loss 3.4233, test loss 3.4233\n",
      "Epoch 57: train loss 3.4233, test loss 3.4232\n",
      "Epoch 58: train loss 3.4232, test loss 3.4231\n",
      "Epoch 59: train loss 3.4231, test loss 3.4230\n",
      "Epoch 60: train loss 3.4230, test loss 3.4230\n",
      "Epoch 61: train loss 3.4230, test loss 3.4229\n",
      "Epoch 62: train loss 3.4229, test loss 3.4228\n",
      "Epoch 63: train loss 3.4228, test loss 3.4227\n",
      "Epoch 64: train loss 3.4227, test loss 3.4226\n",
      "Epoch 65: train loss 3.4226, test loss 3.4226\n",
      "Epoch 66: train loss 3.4226, test loss 3.4225\n",
      "Epoch 67: train loss 3.4225, test loss 3.4224\n",
      "Epoch 68: train loss 3.4224, test loss 3.4223\n",
      "Epoch 69: train loss 3.4223, test loss 3.4223\n",
      "Epoch 70: train loss 3.4223, test loss 3.4222\n",
      "Epoch 71: train loss 3.4222, test loss 3.4221\n",
      "Epoch 72: train loss 3.4221, test loss 3.4220\n",
      "Epoch 73: train loss 3.4220, test loss 3.4220\n",
      "Epoch 74: train loss 3.4220, test loss 3.4219\n",
      "Epoch 75: train loss 3.4219, test loss 3.4218\n",
      "Epoch 76: train loss 3.4218, test loss 3.4217\n",
      "Epoch 77: train loss 3.4217, test loss 3.4217\n",
      "Epoch 78: train loss 3.4217, test loss 3.4216\n",
      "Epoch 79: train loss 3.4216, test loss 3.4215\n",
      "Epoch 80: train loss 3.4215, test loss 3.4214\n",
      "Epoch 81: train loss 3.4214, test loss 3.4214\n",
      "Epoch 82: train loss 3.4214, test loss 3.4213\n",
      "Epoch 83: train loss 3.4213, test loss 3.4212\n",
      "Epoch 84: train loss 3.4212, test loss 3.4211\n",
      "Epoch 85: train loss 3.4211, test loss 3.4211\n",
      "Epoch 86: train loss 3.4211, test loss 3.4210\n",
      "Epoch 87: train loss 3.4210, test loss 3.4209\n",
      "Epoch 88: train loss 3.4209, test loss 3.4208\n",
      "Epoch 89: train loss 3.4208, test loss 3.4208\n",
      "Epoch 90: train loss 3.4208, test loss 3.4207\n",
      "Epoch 91: train loss 3.4207, test loss 3.4206\n",
      "Epoch 92: train loss 3.4206, test loss 3.4205\n",
      "Epoch 93: train loss 3.4205, test loss 3.4205\n",
      "Epoch 94: train loss 3.4205, test loss 3.4204\n",
      "Epoch 95: train loss 3.4204, test loss 3.4203\n",
      "Epoch 96: train loss 3.4203, test loss 3.4202\n",
      "Epoch 97: train loss 3.4202, test loss 3.4201\n",
      "Epoch 98: train loss 3.4201, test loss 3.4201\n",
      "Epoch 99: train loss 3.4201, test loss 3.4200\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss_accumulator = 0.0\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss_value = criterion(output, y)\n",
    "        train_loss_accumulator += loss_value.item()  # Sum the loss for each batch\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_train_loss = train_loss_accumulator / len(train_dl)  # Calculate the average loss\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            total_test_loss += criterion(output, y).item()\n",
    "    average_test_loss = total_test_loss / len(test_dl)\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss {average_train_loss:.4f}, test loss {average_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 358812640870400.0000\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_X, test_Y = get_xy(test_df)\n",
    "    test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "    test_output = model(test_X)\n",
    "    test_loss = criterion(test_output, test_Y)\n",
    "    print(f'Test loss: {test_loss.item():.4f}')\n",
    "\n",
    "    test_df['prediction'] = test_output.cpu().numpy()\n",
    "    test_df['error'] = test_df['prediction'] - test_df['article_count']\n",
    "    test_df['abs_error'] = test_df['error'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_count</th>\n",
       "      <th>event_date</th>\n",
       "      <th>title_embed</th>\n",
       "      <th>summary_embed</th>\n",
       "      <th>lang_deu</th>\n",
       "      <th>lang_eng</th>\n",
       "      <th>lang_spa</th>\n",
       "      <th>lang_zho</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "      <th>abs_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e_11</th>\n",
       "      <td>7</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>[[0.47470707, -0.08501352, 0.26899937, -0.3635...</td>\n",
       "      <td>[[0.3377615, -0.26158097, 0.3140225, -0.212071...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18942358.0</td>\n",
       "      <td>18942351.0</td>\n",
       "      <td>18942351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_15</th>\n",
       "      <td>8</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>[[0.3985864, -0.06734807, 0.40732777, -0.46121...</td>\n",
       "      <td>[[0.5053371, -0.062929116, 0.27972195, -0.4317...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18942358.0</td>\n",
       "      <td>18942350.0</td>\n",
       "      <td>18942350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_count    event_date  \\\n",
       "id                                 \n",
       "e_11             7  1.387325e+09   \n",
       "e_15             8  1.387325e+09   \n",
       "\n",
       "                                            title_embed  \\\n",
       "id                                                        \n",
       "e_11  [[0.47470707, -0.08501352, 0.26899937, -0.3635...   \n",
       "e_15  [[0.3985864, -0.06734807, 0.40732777, -0.46121...   \n",
       "\n",
       "                                          summary_embed  lang_deu  lang_eng  \\\n",
       "id                                                                            \n",
       "e_11  [[0.3377615, -0.26158097, 0.3140225, -0.212071...     False      True   \n",
       "e_15  [[0.5053371, -0.062929116, 0.27972195, -0.4317...     False      True   \n",
       "\n",
       "      lang_spa  lang_zho  prediction       error   abs_error  \n",
       "id                                                            \n",
       "e_11     False     False  18942358.0  18942351.0  18942351.0  \n",
       "e_15     False     False  18942358.0  18942350.0  18942350.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
