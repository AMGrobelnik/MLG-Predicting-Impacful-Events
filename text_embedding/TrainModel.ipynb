{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, n_langs=4, llm_embed_size=768, dropout=0.1):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_dim = n_langs + 2*llm_embed_size + 1 # timestamp\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(in_features=self.input_dim, out_features=1024) # First hidden layer\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(1024, 512) # Second hidden layer\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(512, 128) # Second hidden layer\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.fc4 = nn.Linear(128, 64) # Second hidden layer\n",
    "        self.dropout4 = nn.Dropout(dropout)\n",
    "        self.fc5 = nn.Linear(64, 1) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Add hidden layers with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = self.dropout3(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        # x = self.dropout4(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_count</th>\n",
       "      <th>event_date</th>\n",
       "      <th>title_embed</th>\n",
       "      <th>summary_embed</th>\n",
       "      <th>lang_deu</th>\n",
       "      <th>lang_eng</th>\n",
       "      <th>lang_spa</th>\n",
       "      <th>lang_zho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e_11</th>\n",
       "      <td>7</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>[[0.47470707, -0.08501352, 0.26899937, -0.3635...</td>\n",
       "      <td>[[0.3377615, -0.26158097, 0.3140225, -0.212071...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_10</th>\n",
       "      <td>221</td>\n",
       "      <td>1.387411e+09</td>\n",
       "      <td>[[0.17094071, -0.18888026, 0.28712985, -0.3610...</td>\n",
       "      <td>[[0.1786896, -0.11662727, 0.19326286, -0.20948...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_13</th>\n",
       "      <td>9</td>\n",
       "      <td>1.387498e+09</td>\n",
       "      <td>[[0.2537402, -0.032281302, 0.37904784, -0.3181...</td>\n",
       "      <td>[[0.026874868, -0.09318099, 0.03552014, -0.026...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.387066e+09</td>\n",
       "      <td>[[0.23880291, 0.03649398, 0.32137018, -0.17099...</td>\n",
       "      <td>[[0.46094257, -0.36103615, 0.31917268, -0.6018...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e_15</th>\n",
       "      <td>8</td>\n",
       "      <td>1.387325e+09</td>\n",
       "      <td>[[0.3985864, -0.06734807, 0.40732777, -0.46121...</td>\n",
       "      <td>[[0.5053371, -0.062929116, 0.27972195, -0.4317...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_count    event_date  \\\n",
       "id                                 \n",
       "e_11             7  1.387325e+09   \n",
       "e_10           221  1.387411e+09   \n",
       "e_13             9  1.387498e+09   \n",
       "e_12             1  1.387066e+09   \n",
       "e_15             8  1.387325e+09   \n",
       "\n",
       "                                            title_embed  \\\n",
       "id                                                        \n",
       "e_11  [[0.47470707, -0.08501352, 0.26899937, -0.3635...   \n",
       "e_10  [[0.17094071, -0.18888026, 0.28712985, -0.3610...   \n",
       "e_13  [[0.2537402, -0.032281302, 0.37904784, -0.3181...   \n",
       "e_12  [[0.23880291, 0.03649398, 0.32137018, -0.17099...   \n",
       "e_15  [[0.3985864, -0.06734807, 0.40732777, -0.46121...   \n",
       "\n",
       "                                          summary_embed  lang_deu  lang_eng  \\\n",
       "id                                                                            \n",
       "e_11  [[0.3377615, -0.26158097, 0.3140225, -0.212071...     False      True   \n",
       "e_10  [[0.1786896, -0.11662727, 0.19326286, -0.20948...     False      True   \n",
       "e_13  [[0.026874868, -0.09318099, 0.03552014, -0.026...     False      True   \n",
       "e_12  [[0.46094257, -0.36103615, 0.31917268, -0.6018...     False      True   \n",
       "e_15  [[0.5053371, -0.062929116, 0.27972195, -0.4317...     False      True   \n",
       "\n",
       "      lang_spa  lang_zho  \n",
       "id                        \n",
       "e_11     False     False  \n",
       "e_10     False     False  \n",
       "e_13     False     False  \n",
       "e_12     False     False  \n",
       "e_15     False     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('../data/text/dataset_embedded.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly drop 75% of the data\n",
    "df = df.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_cols = ['lang_eng', 'lang_deu', 'lang_spa', 'lang_zho']\n",
    "x_cols = ['event_date', 'title_embed', 'summary_embed']\n",
    "y_cols = ['article_count']\n",
    "def get_xy(df):\n",
    "    date = df['event_date'].values\n",
    "    langs = df[lang_cols].values\n",
    "    langs = torch.tensor(langs, dtype=torch.bool)\n",
    "    date = torch.tensor(date, dtype=torch.float64)\n",
    "    date = date.unsqueeze(1)\n",
    "\n",
    "    title_embeds = torch.tensor(df['title_embed'].values.tolist(), dtype=torch.float64).reshape(-1, 768)\n",
    "    summary_embeds = torch.tensor(df['summary_embed'].values.tolist(), dtype=torch.float64).reshape(-1, 768)\n",
    "\n",
    "    X = torch.cat((date, langs, title_embeds, summary_embeds), dim=1)\n",
    "    Y = df[y_cols].to_numpy(dtype=np.float32)\n",
    "    return X.float(), torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83745/279429715.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  title_embeds = torch.tensor(df['title_embed'].values.tolist(), dtype=torch.float64).reshape(-1, 768)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = get_xy(train_df)\n",
    "test_X, test_Y = get_xy(test_df)\n",
    "\n",
    "train_ds = TensorDataset(train_X, train_Y)\n",
    "test_ds = TensorDataset(test_X, test_Y)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 3702122590.8591, test loss 707.3087\n",
      "Epoch 1: train loss 642.4339, test loss 707.3087\n",
      "Epoch 2: train loss 642.4093, test loss 707.3087\n",
      "Epoch 3: train loss 642.4351, test loss 707.3087\n",
      "Epoch 4: train loss 642.4152, test loss 707.3087\n",
      "Epoch 5: train loss 642.4051, test loss 707.3087\n",
      "Epoch 6: train loss 642.4236, test loss 707.3087\n",
      "Epoch 7: train loss 642.4215, test loss 707.3087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb Cell 13\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m loss_value \u001b[39m=\u001b[39m criterion(output, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m train_loss_accumulator \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_value\u001b[39m.\u001b[39mitem()  \u001b[39m# Sum the loss for each batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# x = self.dropout1(x)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc2(x))\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# x = self.dropout2(x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-space-enigma-6vgvwx5754pc4j74/workspaces/MLG-Predicting-Impacful-Events/text_embedding/TrainModel.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss_accumulator = 0.0\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss_value = criterion(output, y)\n",
    "        train_loss_accumulator += loss_value.item()  # Sum the loss for each batch\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_train_loss = train_loss_accumulator / len(train_dl)  # Calculate the average loss\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            total_test_loss += criterion(output, y).item()\n",
    "    average_test_loss = total_test_loss / len(test_dl)\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss {average_train_loss:.4f}, test loss {average_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 708.2887\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_X, test_Y = get_xy(test_df)\n",
    "    test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "    test_output = model(test_X)\n",
    "    test_loss = criterion(test_output, test_Y)\n",
    "    print(f'Test loss: {test_loss.item():.4f}')\n",
    "\n",
    "    test_df['prediction'] = test_output.cpu().numpy()\n",
    "    test_df['error'] = test_df['prediction'] - test_df['article_count']\n",
    "    test_df['abs_error'] = test_df['error'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
