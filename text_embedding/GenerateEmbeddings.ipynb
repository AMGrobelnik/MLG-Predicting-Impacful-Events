{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "LvDwnGwAbeFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import extract_text\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "# from preprocess import save_df_to_pickle\n",
        "import pickle\n",
        "import gc"
      ],
      "metadata": {
        "id": "p6ycv6bWaIYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dowload and process data"
      ],
      "metadata": {
        "id": "9LHgDu6Ni7AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "def download_file_from_dropbox(url, destination):\n",
        "    r = requests.get(url)\n",
        "    if r.status_code == 200:\n",
        "        with open(destination, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "    else:\n",
        "        print(f\"Failed to download file, status code: {r.status_code}\")\n",
        "\n",
        "def unzip_file(zip_filepath, dest_directory):\n",
        "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
        "        zip_ref.extractall(dest_directory)\n",
        "\n",
        "dropbox_url = \"https://www.dropbox.com/scl/fi/pd4lj3edgdwdeun3ngdvd/text.pkl?rlkey=7xu6jr2nktlxxahp5mse6vpkh&dl=1\"\n",
        "destination = 'text.pkl'\n",
        "download_file_from_dropbox(dropbox_url, destination)\n",
        "# unzip_file(destination, './data')"
      ],
      "metadata": {
        "id": "yCQTvpdTlWEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract():\n",
        "#     directory_path = \"./data\"\n",
        "#     output_dir = \"./text\"\n",
        "\n",
        "#     files = sorted(os.listdir(directory_path))\n",
        "#     columns = [\"id\", \"lang\", \"title\", \"summary\", \"article_count\"]\n",
        "#     data = pd.DataFrame(columns=columns)\n",
        "#     data.set_index(\"id\", inplace=True)\n",
        "\n",
        "#     for filename in tqdm(files, ncols=100, desc=\"Processing\"):\n",
        "#         file_path = os.path.join(directory_path, filename)\n",
        "#         file_name = os.path.splitext(filename)[0]\n",
        "#         if file_path.endswith(\".pkl\"):\n",
        "#             df = extract_text.extract_text(file_path)\n",
        "#             data = pd.concat([data, df])\n",
        "\n",
        "#     save_df_to_pickle(df, output_dir, 'text')"
      ],
      "metadata": {
        "id": "KTZW9kHZZfTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract()"
      ],
      "metadata": {
        "id": "JcLGEXQoZ6Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embed"
      ],
      "metadata": {
        "id": "xGwfpqehjCUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\").to(device)\n",
        "\n",
        "def generate_embedding(text):\n",
        "  encoded_input = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
        "  output = model(**encoded_input)\n",
        "  return output[1]"
      ],
      "metadata": {
        "id": "tuItVTa3edYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_pickle(data, folder, filename):\n",
        "    if not os.path.exists(folder):\n",
        "      os.makedirs(folder)\n",
        "    with open(f\"{folder}/{filename}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(data, f)"
      ],
      "metadata": {
        "id": "KQc9AWxGiT8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 1000\n",
        "\n",
        "# Load data\n",
        "data = pd.read_pickle(\"./text.pkl\")\n",
        "\n",
        "# Initialize the list to hold the dictionaries\n",
        "embeddings = {}\n",
        "\n",
        "# Processing loop\n",
        "for b in tqdm(range(0, len(data), chunk_size), desc=\"Processing batches\", ncols=100):\n",
        "    batch = data.iloc[b:b+chunk_size]\n",
        "\n",
        "    # Generate embeddings and store them in the list along with IDs\n",
        "    for i, row in batch.iterrows():\n",
        "        embeddings[i] = {\n",
        "            'title_embed': generate_embedding(row[\"title\"]).cpu().detach().numpy(),  # Move to CPU and detach\n",
        "            'summary_embed': generate_embedding(row[\"summary\"]).cpu().detach().numpy()  # Move to CPU and detach\n",
        "        }\n",
        "\n",
        "    # Explicitly free GPU memory\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Save the generated embeddings to disk and clear the list\n",
        "    save_to_pickle(embeddings, './embeds', f'batch_{b}')\n",
        "    embeddings.clear()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ELI7inceI8b",
        "outputId": "3b6a293b-b0b5-420f-fa1a-5532fe25db22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|███████████████████████████████████████| 195/195 [1:40:45<00:00, 31.00s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip"
      ],
      "metadata": {
        "id": "oycKPJaysuKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def zip_folder(folder_path, zip_path):\n",
        "    # Create a zip file from the folder\n",
        "    shutil.make_archive(zip_path, 'zip', folder_path)"
      ],
      "metadata": {
        "id": "EyhUTuzFg_4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('./embeds', 'embeds')"
      ],
      "metadata": {
        "id": "k-5T3IkOr0n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -A"
      ],
      "metadata": {
        "id": "qKCpIaiir5cT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18d25d1-7ecc-4c81-b1c7-0d79f0046a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config  embeds  embeds.zip  sample_data  text.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh embeds.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6V3tylKe8i",
        "outputId": "b707a627-b04f-4a85-c9dd-4fd6cf74293c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1G\tembeds.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwjNhVxLKo2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}